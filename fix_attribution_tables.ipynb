{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import functions.core_functions as core_functions\n",
    "import functions.pyarrow_functions as pyarrow_functions\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe.utils import assert_eq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import json\n",
    "import gc\n",
    "import cudf\n",
    "import os\n",
    "import yaml\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "import uu\n",
    "\n",
    "dask.config.set({\"dataframe.backend\": \"cudf\"})\n",
    "\n",
    "importlib.reload(core_functions)\n",
    "importlib.reload(pyarrow_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_schema = yaml.safe_load(open('table-schemas.yaml'))\n",
    "\n",
    "detections_python = table_schema['detections_python_schema']\n",
    "detections_python\n",
    "\n",
    "n90_schema_dict = {item['name']: item['type'] for item in detections_python}\n",
    "veil_schema_dict = {item['name']: item['type'] for item in detections_python if 'geo_' not in item['name']}\n",
    "final_detections_cols = []\n",
    "for item in detections_python:\n",
    "    final_detections_cols.append(item['name'])\n",
    "    # print(f\"{item['name']} = {item['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = {}\n",
    "resp = core_functions.initialize_clients(service_account_secret_name='SA_ADHOC_BILLING')\n",
    "resp2 = core_functions.initialize_clients(service_account_secret_name='SA_N90_CORE_APPS')\n",
    "\n",
    "config = resp.get('config')\n",
    "bigquery_client = resp.get('clients').get('bigquery_client')\n",
    "n90_bigquery_client = resp2.get('clients').get('bigquery_client')\n",
    "storage_client = resp.get('clients').get('storage_client')\n",
    "sf_client = resp.get('clients').get('sf_client')\n",
    "veil_billing = resp.get('config').get('veil_billing')\n",
    "veil_vars = resp.get('config').get('veil_billing').get('vars')\n",
    "# print(veil_billing)\n",
    "sfdc_adv_account_cols = veil_billing.get('vars').get('sfdc_adv_account_cols')\n",
    "sfdc_rate_card_cols = veil_billing.get('vars').get('sfdc_rate_card_cols')\n",
    "unknown_dma_overrides = config.get('national_dma_overrides_to_us_national')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_ADHOC_BILLING')\n",
    "# broadcast_cal_sql = f\"\"\"\n",
    "#     SELECT id as bcw_id, bcw_index, bcm_index, bcw_start_date, bcw_end_date FROM `adhoc-billing.avs_billing_process.lu_broadcast_week`\n",
    "# \"\"\"\n",
    "# broadcast_cal_df = core_functions.fetch_gbq_data(query=broadcast_cal_sql, bigquery_client=bigquery_client)\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_N90_CORE_APPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_N90_CORE_APPS')\n",
    "geo_zip_sql = f\"\"\"\n",
    "    SELECT *\n",
    "    from `next90-core-applications.next90_analytics.geos` WHERE geo_type = 'zip'\n",
    "    AND geo_country in ('United States', 'Canada')\n",
    "\"\"\"\n",
    "geo_zip_df = core_functions.fix_df_dtypes(core_functions.fetch_gbq_data(query=geo_zip_sql, bigquery_client=n90_bigquery_client))\n",
    "\n",
    "geo_dma_sql = f\"\"\"\n",
    "    SELECT *\n",
    "    from `next90-core-applications.next90_analytics.geos` WHERE geo_type = 'dma'\n",
    "    AND geo_country in ('United States', 'Canada')\n",
    "\"\"\"\n",
    "geo_dma_df = core_functions.fix_df_dtypes(core_functions.fetch_gbq_data(query=geo_dma_sql, bigquery_client=n90_bigquery_client))\n",
    "\n",
    "\n",
    "# int_cols = ['geo_neustar_id','geo_us_msa_id', 'geo_us_county_fips_id','geo_ca_cma_id']\n",
    "# for col in int_cols:\n",
    "#     geo_zip_df[col] = geo_df[col].fillna(-1).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_N90_CORE_APPS')\n",
    "broadcast_cal_sql = f\"\"\"\n",
    "    SELECT id as bcw_id, bcw_index, bcm_index, bcw_start_date, bcw_end_date FROM `next90-core-applications.n90_data_lake.lu_broadcast_week`\n",
    "\"\"\"\n",
    "broadcast_cal_df = core_functions.fetch_gbq_data(query=broadcast_cal_sql, bigquery_client=n90_bigquery_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_dma_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start_date = '2024-11-01'\n",
    "data_end_date = '2024-12-01'\n",
    "\n",
    "process_sql = f\"\"\"\n",
    "    SELECT distinct EXTRACT(YEAR FROM created_time) as year, EXTRACT(MONTH FROM created_time) as month, EXTRACT(DAY FROM created_time) as  day\n",
    " from `next90-core-applications.n90_data_lake.activity_sessions`\n",
    "    WHERE created_time >= '{data_start_date}' and created_time < '{data_end_date}'\n",
    "    order by year, month, day\n",
    "\"\"\"\n",
    "\n",
    "process_df = core_functions.fetch_gbq_data(process_sql, n90_bigquery_client)\n",
    "process_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_days = process_df.to_dict(orient='records')\n",
    "process_days\n",
    "for record in process_days:\n",
    "    print(f'year: {record[\"year\"]}, month: {record[\"month\"]}, day: {record[\"day\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_days[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_activity_sessions_segments(df, _bcc_df, geo_z_df, geo_d_df, media='DIGITAL'):\n",
    "    df['key'] = 1\n",
    "    _bcc_df['key'] = 1\n",
    "    df['activity_date_time'] = pd.to_datetime(df['created_time'])\n",
    "    _bcc_df['bcw_start_date'] = pd.to_datetime(_bcc_df['bcw_start_date'])\n",
    "    _bcc_df['bcw_end_date'] = pd.to_datetime(_bcc_df['bcw_end_date'])\n",
    "    ref_df = None\n",
    "    ref_df = _bcc_df.loc[(_bcc_df['bcw_start_date'] >= df['activity_date_time'].min()) & (_bcc_df['bcw_end_date'] <= df['activity_date_time'].max())]\n",
    "    merged_df = None\n",
    "    merged_df = pd.merge(df, ref_df, on='key').drop(['key', 'activity_date_time'], axis=1)\n",
    "    merged_df.sort_values(by=['id'], inplace=True)\n",
    "    merged_df = merged_df.drop_duplicates(subset=['id'], keep='first')\n",
    "    merged_df['bc_year_index'] = merged_df['bcm_index'].astype(str).str[:4].astype('Int64')\n",
    "    merged_df['bcm_index'] = merged_df['bcm_index'].astype('Float64')\n",
    "    merged_df['bcw_index'] = merged_df['bcw_index'].astype('Float64')\n",
    "    del merged_df\n",
    "    gc.collect()\n",
    "    df = merged_df\n",
    "    df['_YEAR'] = df['created_time'].dt.year.astype('Int64')\n",
    "    df['_MONTH'] = df['created_time'].dt.month.astype('Int64')\n",
    "    df['_DAY'] = df['created_time'].dt.day.astype('Int64')\n",
    "    \n",
    "    activity_sessions_with_geos_df = df.merge(geo_z_df, how='left', left_on='zip_code', right_on='geo_location')\n",
    "    del df\n",
    "    gc.collect()\n",
    "    activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('string')\n",
    "    activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()] = activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()].merge(geo_d_df, how='left', left_on='neustar_dma_id', right_on='geo_location')\n",
    "    activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('Int64')\n",
    "    activity_sessions_with_geos_df.sort_values(by=['id', 'created_time'], ascending=[True, False] ,inplace=True)\n",
    "    df = activity_sessions_with_geos_df.drop_duplicates(subset=['id'], keep='first').sort_values(by='created_time').copy().reset_index(drop=True)\n",
    "    del activity_sessions_with_geos_df\n",
    "    gc.collect()\n",
    "    df['segments_date'] = pd.to_datetime(df['created_time'])\n",
    "    df['segments_day_of_week'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.day_name().astype('string')\n",
    "    df['segments_media'] =  media\n",
    "        \n",
    "    df['segments_month_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('M').astype('string')\n",
    "    df['segments_quarter_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Q').astype('string')\n",
    "    df['segments_week_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('W').astype('string')\n",
    "\n",
    "    # Convert timestamp to periods and then use start_time to get the first day of the period\n",
    "    df['segments_month'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('M').dt.start_time.dt.date.astype('string')\n",
    "    df['segments_quarter'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Q').dt.start_time.dt.date.astype('string')\n",
    "    df['segments_week'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('W').dt.start_time.dt.date.astype('string')\n",
    "\n",
    "    # Year can remain as a period or also be converted similarly if needed\n",
    "    df['segments_year'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Y').astype('string')\n",
    "    df['segments_broadcast_year'] = df['bc_year_index'].astype('Int64')\n",
    "    df['segments_broadcast_month_index'] = df['bcm_index'].astype('Float64')\n",
    "    df['segments_broadcast_week_index'] = df['bcw_index'].astype('Float64')\n",
    "    df['_YEAR'] = df['segments_date'].dt.year.astype('Int64')\n",
    "    df['_MONTH'] = df['segments_date'].dt.month.astype('Int64')\n",
    "    df['_DAY'] = df['segments_date'].dt.day.astype('Int64')\n",
    "    df['segments_date'] = df['segments_date'].dt.date.astype('string')\n",
    "    df['session_timestamp'] = df['date_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['date_time'] = df['date_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df['last_updated'] = df['billing_last_updated'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['last_updated_audit_id'] = uuid.uuid4()\n",
    "    df['bcw_start_date'] = df['bcw_start_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['bcw_end_date'] = df['bcw_end_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_activity_sessions_segments(_df, _bcc_df, geo_z_df, geo_d_df, media='DIGITAL'):\n",
    "    print('starting process_activity_sessions_segments')\n",
    "    print('adding broadcast cal details')\n",
    "    print(f'length of df: {len(_df)}')\n",
    "    _df['key'] = 1\n",
    "    _bcc_df['key'] = 1\n",
    "    _df['activity_date_time'] = pd.to_datetime(_df['created_time'])\n",
    "    _bcc_df['bcw_start_date'] = pd.to_datetime(_bcc_df['bcw_start_date'])\n",
    "    _bcc_df['bcw_end_date'] = pd.to_datetime(_bcc_df['bcw_end_date'])\n",
    "    # ref_df = None\n",
    "    ref_df = _bcc_df.loc[(_bcc_df['bcw_start_date'] >= _df['created_time'].min()) & (_bcc_df['bcw_end_date'] <= _df['created_time'].max())]\n",
    "    # merged_df = None\n",
    "    merged_df = pd.merge(_df, ref_df, on='key').drop(['key', 'created_time'], axis=1)\n",
    "    merged_df['bc_year_index'] = merged_df['bcm_index'].astype(str).str[:4].astype('Int64')\n",
    "    merged_df['bcm_index'] = merged_df['bcm_index'].astype('Float64')\n",
    "    merged_df['bcw_index'] = merged_df['bcw_index'].astype('Float64')\n",
    "\n",
    "    merged_df.sort_values(by=['id'], inplace=True)\n",
    "    merged_df = merged_df.drop_duplicates(subset=['id'], keep='first')\n",
    "    # df = merged_df\n",
    "    # print('finished adding broadcast cal details')\n",
    "    # print(f'length of df: {len(df)}')\n",
    "    # del merged_df\n",
    "    # gc.collect()\n",
    "    # df['_YEAR'] = df['created_time'].dt.year.astype('Int64')\n",
    "    # df['_MONTH'] = df['created_time'].dt.month.astype('Int64')\n",
    "    # df['_DAY'] = df['created_time'].dt.day.astype('Int64')\n",
    "    # print('adding geos')\n",
    "    # activity_sessions_with_geos_df = df.merge(geo_z_df, how='left', left_on='zip_code', right_on='geo_location')\n",
    "    # del df\n",
    "    # gc.collect()\n",
    "    # activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('string')\n",
    "    # activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()] = activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()].merge(geo_d_df, how='left', left_on='neustar_dma_id', right_on='geo_location')\n",
    "    # activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('Int64')\n",
    "    # activity_sessions_with_geos_df.sort_values(by=['id', 'created_time'], ascending=[True, False] ,inplace=True)\n",
    "    # df = activity_sessions_with_geos_df.drop_duplicates(subset=['id'], keep='first').sort_values(by='created_time').copy().reset_index(drop=True)\n",
    "    # del activity_sessions_with_geos_df\n",
    "    # gc.collect()\n",
    "    # print('adding segments')\n",
    "    # df['segments_date'] = pd.to_datetime(df['created_time'])\n",
    "    # df['segments_day_of_week'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.day_name().astype('string')\n",
    "    # df['segments_media'] =  media\n",
    "        \n",
    "    # df['segments_month_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('M').astype('string')\n",
    "    # df['segments_quarter_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Q').astype('string')\n",
    "    # df['segments_week_label'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('W').astype('string')\n",
    "\n",
    "    # # Convert timestamp to periods and then use start_time to get the first day of the period\n",
    "    # df['segments_month'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('M').dt.start_time.dt.date.astype('string')\n",
    "    # df['segments_quarter'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Q').dt.start_time.dt.date.astype('string')\n",
    "    # df['segments_week'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('W').dt.start_time.dt.date.astype('string')\n",
    "\n",
    "    # # Year can remain as a period or also be converted similarly if needed\n",
    "    # df['segments_year'] = pd.to_datetime(df['segments_date']).dt.tz_localize(None).dt.to_period('Y').astype('string')\n",
    "    # df['segments_broadcast_year'] = df['bc_year_index'].astype('Int64')\n",
    "    # df['segments_broadcast_month_index'] = df['bcm_index'].astype('Float64')\n",
    "    # df['segments_broadcast_week_index'] = df['bcw_index'].astype('Float64')\n",
    "    # df['_YEAR'] = df['segments_date'].dt.year.astype('Int64')\n",
    "    # df['_MONTH'] = df['segments_date'].dt.month.astype('Int64')\n",
    "    # df['_DAY'] = df['segments_date'].dt.day.astype('Int64')\n",
    "    # df['segments_date'] = df['segments_date'].dt.date.astype('string')\n",
    "    # df['session_timestamp'] = df['created_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # df['created_time'] = df['created_time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # df['bcw_start_date'] = df['bcw_start_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # df['bcw_end_date'] = df['bcw_end_date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    # print('finished process_activity_sessions_segments')\n",
    "    \n",
    "\n",
    "    return _df\n",
    "\n",
    "\n",
    "process_days = [{'year': 2024, 'month': 11, 'day': 1}]\n",
    "for record in process_days:\n",
    "    year = record['year']\n",
    "    month = record['month']\n",
    "    day = record['day']\n",
    "    print(f'Processing year: {year}, month: {month}')\n",
    "\n",
    "    # activity_sessions_sql = f\"\"\"\n",
    "    #     WITH brandToEncoding AS (\n",
    "    #     SELECT distinct\n",
    "    #     t.brand_id, t.aeis_id, e.encoding_id, e.sfdc_account_id, e.sfdc_account_name, e.sfdc_advertiser_id\n",
    "    #     FROM `next90-core-applications.omniData.first_party_triggers` t\n",
    "    #     join `next90-core-applications.omniData.avs_encodings` e\n",
    "    #     on cast(t.aeis_id as INT64) = e.aeis_id\n",
    "    #     )\n",
    "\n",
    "    #     SELECT distinct a.*, sfdc_account_id, sfdc_account_name, sfdc_advertiser_id,  p.ip_address\n",
    "    #     FROM `next90-core-applications.omniData.activity_sessions` a\n",
    "    #     JOIN `next90-core-applications.omniData.pageviews` p\n",
    "    #     on a.session_id = p.activity_session_id\n",
    "    #     left join brandToEncoding b\n",
    "    #     on a.brand_id = b.brand_id\n",
    "    #     WHERE EXTRACT(YEAR FROM created_time) = {year} and EXTRACT(MONTH FROM created_time) = {month}  and EXTRACT(DAY FROM created_time) = {day}\n",
    "    # \"\"\"\n",
    "    activity_sessions_sql = f\"\"\"\n",
    "        SELECT *,\n",
    "            TIMESTAMP_TRUNC(created_time, SECOND) AS activity_session_timestamp,\n",
    "            --- CONCAT(EXTRACT(YEAR FROM created_time), '-', FORMAT('%02d', EXTRACT(MONTH FROM created_time))) AS process_month_group\n",
    "        FROM `next90-core-applications.omniData.temp_activity_sessions`\n",
    "        WHERE EXTRACT(YEAR FROM created_time) = {year} \n",
    "        AND EXTRACT(MONTH FROM created_time) = {month}\n",
    "    \"\"\"\n",
    "    \n",
    "    print('loading activity sessions')\n",
    "    activity_sessions_df = core_functions.fetch_gbq_data(activity_sessions_sql, n90_bigquery_client)\n",
    "    activity_sessions_df.sort_values(by=['id', 'created_time'], ascending=[True, False] ,inplace=True)\n",
    "    activity_sessions_df = activity_sessions_df.drop_duplicates(subset=['id'], keep='first')\n",
    "    # activity_sessions_df = activity_sessions_df[0:1000]\n",
    "    print('processing with function process_activity_sessions_segments')\n",
    "    # activity_sessions_df = process_activity_sessions_segments(activity_sessions_df, broadcast_cal_df, geo_zip_df, geo_dma_df)\n",
    "    \n",
    "    # billing_last_updated = pd.Timestamp.utcnow()\n",
    "    # activity_sessions_df['activity_session_last_updated'] = billing_last_updated\n",
    "    # billing_last_audit_id = core_functions.generate_uuid()\n",
    "    # activity_sessions_df['activity_session_last_audit_id'] = billing_last_audit_id\n",
    "    # # print('adding broadcast cal details')\n",
    "    \n",
    "\n",
    "    activity_sessions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27331840\n",
    "# 27331844\n",
    "# 27331840\n",
    "activity_sessions_df.sort_values(by=['id', 'created_time'], ascending=[True, False] ,inplace=True)\n",
    "activity_sessions_df = activity_sessions_df.drop_duplicates(subset=['id'], keep='first')\n",
    "activity_sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_df['_YEAR'] = activity_sessions_df['created_time'].dt.year.astype('Int64')\n",
    "activity_sessions_df['_MONTH'] = activity_sessions_df['created_time'].dt.month.astype('Int64')\n",
    "activity_sessions_df['_DAY'] = activity_sessions_df['created_time'].dt.day.astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_with_geos_df = activity_sessions_df.merge(geo_zip_df, how='left', left_on='zip_code', right_on='geo_location')\n",
    "activity_sessions_with_geos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()]\n",
    "activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('string')\n",
    "activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()] = activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()].merge(geo_dma_df, how='left', left_on='neustar_dma_id', right_on='geo_location')\n",
    "activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('Int64')\n",
    "activity_sessions_with_geos_df.loc[activity_sessions_with_geos_df['neustar_country'].isin(['us', 'ca']) & activity_sessions_with_geos_df['geo_country'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_with_geos_df['neustar_dma_id'] = activity_sessions_with_geos_df['neustar_dma_id'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_df['created_time_2'] = pd.to_datetime(activity_sessions_df['created_time'])\n",
    "broadcast_cal_df['bcw_start_date_2'] = pd.to_datetime(broadcast_cal_df['bcw_start_date'])\n",
    "broadcast_cal_df['bcw_end_date_2'] = pd.to_datetime(broadcast_cal_df['bcw_end_date'])\n",
    "\n",
    "\n",
    "activity_sessions_df['created_time'].max()\n",
    "activity_sessions_df['_YEAR'] = activity_sessions_df['created_time'].dt.year.astype('string')\n",
    "activity_sessions_df['_MONTH'] = activity_sessions_df['created_time'].dt.month.astype('string')\n",
    "\n",
    "ref_1_ids_df = broadcast_cal_df[broadcast_cal_df['bcw_start_date_2'] <= activity_sessions_df['created_time_2'].min()]\n",
    "ref_2_ids_df = broadcast_cal_df[broadcast_cal_df['bcw_end_date_2'] > activity_sessions_df['created_time_2'].max()]\n",
    "ref_1_ids_df\n",
    "# common_ids = []\n",
    "# for id in ref_1_ids:\n",
    "#     if id in ref_2_ids:\n",
    "#         common_ids.append(id)\n",
    "# common_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_df['created_time'] = activity_sessions_df['created_time'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_sessions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_cal_df['bcw_start_date'] = pd.to_datetime(broadcast_cal_df['bcw_start_date'])\n",
    "broadcast_cal_df['bcw_end_date'] = pd.to_datetime(broadcast_cal_df['bcw_end_date'])\n",
    "activity_sessions_df['created_time'] = pd.to_datetime(activity_sessions_df['created_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_min_date = pd.to_datetime(activity_sessions_df['created_time']).min()\n",
    "ref_max_date = pd.to_datetime(activity_sessions_df['created_time']).max()\n",
    "ref_max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_1 = broadcast_cal_df[(broadcast_cal_df['bcw_start_date'] <= ref_min_date)]\n",
    "# ref_2 = ref_1.loc[(ref_1['bcw_end_date'] < ref_max_date)].copy()\n",
    "ref_1\n",
    "# broadcast_cal_df.loc[(broadcast_cal_df['bcw_start_date'] >= activity_sessions_df['created_time'].min()) & (broadcast_cal_df['bcw_end_date'] <= activity_sessions_df['created_time'].max())]\n",
    "# # Get scalar values for the date range\n",
    "# min_created_time = activity_sessions_df['created_time'].min()\n",
    "# max_created_time = activity_sessions_df['created_time'].max()\n",
    "\n",
    "# # Filter the DataFrame\n",
    "# filtered_broadcast_cal_df = broadcast_cal_df.loc[\n",
    "#     (broadcast_cal_df['bcw_start_date'] >= min_created_time) &\n",
    "#     (broadcast_cal_df['bcw_end_date'] <= max_created_time)\n",
    "# ]\n",
    "# filtered_broadcast_cal_df\n",
    "# # reff_df\n",
    "# # activity_sessions_df['created_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = broadcast_cal_df\n",
    "for col in ddf.columns:\n",
    "    print(f'col: {col}, dtype: {ddf[col].dtype}, sample: {ddf[col].iloc[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
