{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import functions.core_functions as core_functions\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe.utils import assert_eq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "import json\n",
    "import gc\n",
    "import cudf\n",
    "\n",
    "dask.config.set({\"dataframe.backend\": \"cudf\"})\n",
    "\n",
    "importlib.reload(core_functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = {}\n",
    "resp = core_functions.initialize_clients()\n",
    "\n",
    "config = resp.get('config')\n",
    "bigquery_client = resp.get('clients').get('bigquery_client')\n",
    "storage_client = resp.get('clients').get('storage_client')\n",
    "sf_client = resp.get('clients').get('sf_client')\n",
    "veil_billing = resp.get('config').get('veil_billing')\n",
    "veil_vars = resp.get('config').get('veil_billing').get('vars')\n",
    "# print(veil_billing)\n",
    "sfdc_adv_account_cols = veil_billing.get('vars').get('sfdc_adv_account_cols')\n",
    "sfdc_rate_card_cols = veil_billing.get('vars').get('sfdc_rate_card_cols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avs_tables = ['encodings', 'encoders', 'encoder_groups', 'formats', 'customers', 'profiles', 'aeismaps']\n",
    "avs_data = core_functions.fetch_table_data(\n",
    "    project_id=veil_billing.get('avs_project_id'),\n",
    "    dataset_id=veil_billing.get('avs_dataset_id'),\n",
    "    table_names=avs_tables,\n",
    "    bigquery_client=bigquery_client\n",
    ")\n",
    "\n",
    "# Access specific DataFrames\n",
    "encodings_df = avs_data['encodings']\n",
    "encoders_df = avs_data['encoders']\n",
    "encoder_groups_df = avs_data['encoder_groups']\n",
    "formats_df = avs_data['formats']\n",
    "customers_df = avs_data['customers']\n",
    "profiles_df = avs_data['profiles']\n",
    "aeismaps_df = avs_data['aeismaps']\n",
    "\n",
    "encoding_format_ids = encodings_df['format_id'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_mask = encodings_df['format_id'] == 13568\n",
    "# encodings_df = encodings_df[test_mask].copy()\n",
    "# encoding_format_ids\n",
    "len(encodings_df)\n",
    "# 1666255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "billing_tables = [\n",
    "    'sfdc_bvs_customer__c_obj',\n",
    "    'sfdc_bvs_format__c_obj',\n",
    "    'sfdc_account_obj',\n",
    "    'sfdc_advertiser__c_obj',\n",
    "    'sfdc_rate_card__c_obj'\n",
    "]\n",
    "billing_data = core_functions.fetch_table_data(\n",
    "    project_id=veil_billing.get('billing_project_id'),\n",
    "    dataset_id=veil_billing.get('billing_dataset_id'),\n",
    "    table_names=billing_tables,\n",
    "    bigquery_client=bigquery_client\n",
    ")\n",
    "\n",
    "# Access specific DataFrames\n",
    "sfdc_bvs_customer_df = billing_data['sfdc_bvs_customer__c_obj']\n",
    "sfdc_account_df = billing_data['sfdc_account_obj']\n",
    "sfdc_advertiser_df = billing_data['sfdc_advertiser__c_obj']\n",
    "sfdc_rate_card_df = billing_data['sfdc_rate_card__c_obj']\n",
    "sfdc_bvs_format_df = billing_data['sfdc_bvs_format__c_obj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameConfig =  core_functions.DataFrameConfig\n",
    "        \n",
    "preprocess_config = {\n",
    "    'encodings_df': DataFrameConfig(\n",
    "        dataframe=encodings_df,\n",
    "        config={\n",
    "            'date_cols': ['encoded_timestamp', 'detection_end_date', 'last_updated'],\n",
    "            'to_epoch_cols': ['encoded_timestamp'],\n",
    "            'int_cols': ['encoding_id', 'encoder_id', 'encoder_group_id', 'format_id', 'clone_of'],\n",
    "            'struct_cols': ['attributes']\n",
    "        }\n",
    "    ),\n",
    "    'encoders_df': DataFrameConfig(\n",
    "        dataframe=encoders_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['encoder_id', 'encoder_group_id']\n",
    "        }\n",
    "    ),\n",
    "    'encoder_groups_df': DataFrameConfig(\n",
    "        dataframe=encoder_groups_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['encoder_group_id']\n",
    "        }\n",
    "    ),\n",
    "    'formats_df': DataFrameConfig(\n",
    "        dataframe=formats_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['format_id', 'profile_id', 'customer_id', 'report_breakup']\n",
    "        }\n",
    "    ),\n",
    "    'customers_df': DataFrameConfig(\n",
    "        dataframe=customers_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['customer_id'],\n",
    "            'bool_cols': ['deleted']\n",
    "        }\n",
    "    ),\n",
    "    'profiles_df': DataFrameConfig(\n",
    "        dataframe=profiles_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['profile_id'],\n",
    "            'bool_cols': ['deleted'],\n",
    "            'str_cols': ['default_asset_code']\n",
    "        }\n",
    "    ),\n",
    "    'aeismaps_df': DataFrameConfig(\n",
    "        dataframe=aeismaps_df,\n",
    "        config={\n",
    "            'date_cols': ['last_updated'],\n",
    "            'int_cols': ['aeis_id', 'encoding_id']\n",
    "        }\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_df.head()\n",
    "len(encodings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all DataFrames\n",
    "processed_dataframes = {}\n",
    "for name, df_config in preprocess_config.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    processed_dataframes[name] = core_functions.preprocess_dataframe(df_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the processed DataFrame\n",
    "processed_encodings_df = processed_dataframes['encodings_df']\n",
    "processed_encoders_df = processed_dataframes['encoders_df']\n",
    "processed_encoder_groups_df = processed_dataframes['encoder_groups_df']\n",
    "processed_formats_df = processed_dataframes['formats_df']\n",
    "processed_customers_df = processed_dataframes['customers_df']\n",
    "processed_profiles_df = processed_dataframes['profiles_df']\n",
    "processed_aeismaps_df = processed_dataframes['aeismaps_df']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_encodings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoding_format_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_processed_encodings_df = core_functions.clean_encodings_df(processed_encodings_df)\n",
    "clean_processed_encodings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_processed_encodings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encodings_df = clean_processed_encodings_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_processed_encodings_df = pd.DataFrame()\n",
    "# for format_id in encoding_format_ids:\n",
    "#     mask = processed_encodings_df['format_id'] == format_id\n",
    "#     print(f\"Processing format_id: {format_id}...\")\n",
    "#     format_df = processed_encodings_df.loc[processed_encodings_df['format_id'] == format_id].copy()\n",
    "#     df = core_functions.clean_encodings_df(format_df)\n",
    "#     clean_processed_encodings_df = pd.concat([clean_processed_encodings_df, df], ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "# # clean_processed_encodings_df = core_functions.clean_encodings_df(processed_encodings_df)\n",
    "# clean_processed_encodings_df\n",
    "\n",
    "# Define conditions\n",
    "# Ensure 'description' column does not contain None values\n",
    "processed_encodings_df = clean_processed_encodings_df.copy()\n",
    "# processed_encodings_df['description'] = processed_encodings_df['attributes_description'].fillna('')\n",
    "# processed_encodings_df['product_code'] = processed_encodings_df['attributes_product_code'].fillna('')\n",
    "\n",
    "# processed_encodings_df['product_name'] = processed_encodings_df['attributes_product_name'].fillna('')\n",
    "# processed_encodings_df['donovan_agency_product_code'] = processed_encodings_df['attributes_donovan_agency_product_code'].fillna('')\n",
    "# processed_encodings_df['isci'] = processed_encodings_df['attributes_isci'].fillna('')\n",
    "# processed_encodings_df['project_name'] = processed_encodings_df['attributes_project_name'].fillna('')\n",
    "# processed_encodings_df['advertiser'] = processed_encodings_df['attributes_advertiser'].fillna('')\n",
    "\n",
    "# processed_encodings_df['client_code'] = processed_encodings_df['attributes_client_code'].fillna('')\n",
    "# processed_encodings_df['donovan_agency_advertiser_code'] = processed_encodings_df['attributes_donovan_agency_advertiser_code'].fillna('')\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     processed_encodings_df['product_code'].notnull(),\n",
    "#     processed_encodings_df['product_code'].isnull() & processed_encodings_df['product_name'].notnull(),\n",
    "#     processed_encodings_df['product_code'].isnull() & processed_encodings_df['product_name'].isnull() & processed_encodings_df['donovan_agency_product_code'].notnull(),\n",
    "#     processed_encodings_df['product_code'].isnull() & processed_encodings_df['product_name'].isnull() & processed_encodings_df['donovan_agency_product_code'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & ~processed_encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     processed_encodings_df['product_code'].isnull() & processed_encodings_df['product_name'].isnull() & processed_encodings_df['donovan_agency_product_code'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & processed_encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     processed_encodings_df['product_code'],\n",
    "#     processed_encodings_df['product_name'],\n",
    "#     processed_encodings_df['donovan_agency_product_code'],\n",
    "#     processed_encodings_df['description'].str[26:30].str.strip(),\n",
    "#     processed_encodings_df['description'].str[6:10].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# processed_encodings_df['product_code'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     processed_encodings_df['isci'].notnull(),\n",
    "#     processed_encodings_df['isci'].isnull() & processed_encodings_df['project_name'].notnull(),\n",
    "#     processed_encodings_df['isci'].isnull() & processed_encodings_df['project_name'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & ~processed_encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     processed_encodings_df['isci'].isnull() & processed_encodings_df['project_name'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & processed_encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     processed_encodings_df['isci'],\n",
    "#     processed_encodings_df['project_name'],\n",
    "#     processed_encodings_df['description'].str[8:18].str.strip(),\n",
    "#     processed_encodings_df['description'].str[18:38].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# processed_encodings_df['isci'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     processed_encodings_df['advertiser'].notnull(),\n",
    "#     processed_encodings_df['advertiser'].isnull() & processed_encodings_df['client_code'].notnull(),\n",
    "#     processed_encodings_df['advertiser'].isnull() & processed_encodings_df['client_code'].isnull() & processed_encodings_df['donovan_agency_advertiser_code'].notnull(),\n",
    "#     processed_encodings_df['advertiser'].isnull() & processed_encodings_df['client_code'].isnull() & processed_encodings_df['donovan_agency_advertiser_code'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & ~processed_encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     processed_encodings_df['advertiser'].isnull() & processed_encodings_df['client_code'].isnull() & processed_encodings_df['donovan_agency_advertiser_code'].isnull() & processed_encodings_df['description'].notnull() & processed_encodings_df['description'].str.len() > 10 & processed_encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     processed_encodings_df['advertiser'],\n",
    "#     processed_encodings_df['client_code'],\n",
    "#     processed_encodings_df['donovan_agency_advertiser_code'],\n",
    "#     processed_encodings_df['description'].str[22:26].str.strip(),\n",
    "#     processed_encodings_df['description'].str[2:6].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# processed_encodings_df['advertiser'] = np.select(conditions, choices, default=None)\n",
    "# processed_encodings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_sfdc_bvs_customer_df = core_functions.clean_sfdc_df(sfdc_bvs_customer_df, id_col='sfdc_bvs_customer_id', name_col='sfdc_bvs_customer_name')\n",
    "clean_sfdc_account_df = core_functions.clean_sfdc_df(sfdc_account_df, id_col='sfdc_account_id', name_col='sfdc_account_name')\n",
    "clean_sfdc_advertiser_df = core_functions.clean_sfdc_df(sfdc_advertiser_df, id_col='sfdc_advertiser_id', name_col='sfdc_advertiser_name')\n",
    "clean_sfdc_rate_card_df = core_functions.clean_sfdc_df(sfdc_rate_card_df, id_col='sfdc_rate_card_id', name_col='rate_card_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_processed_encodings_df = core_functions.clean_encodings_df(processed_encodings_df)\n",
    "# processed_encodings_df['attributes_product_code']\n",
    "processed_encodings_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sfdc_account_df\n",
    "\n",
    "clean_sfdc_account_df.sort_values(by='sfdc_account_id', inplace=True)\n",
    "\n",
    "# sfdc_advertiser_df['sfdc_advertiser_id'] = sfdc_advertiser_df['id']\n",
    "# sfdc_advertiser_df['sfdc_advertiser_name'] = sfdc_advertiser_df['name']\n",
    "# sfdc_advertiser_df['sfdc_account_id'] = sfdc_advertiser_df['account']\n",
    "\n",
    "clean_sfdc_advertiser_df.sort_values(by=['sfdc_account_id', 'sfdc_advertiser_id', 'encoding_format_id', 'encoding_advertiser', 'encoding_product_code', 'encoding_module_code'], inplace=True)\n",
    "# # # sfdc_account_df[['sfdc_account_id', 'sfdc_account_name']] \n",
    "clean_sfdc_adv_account_df = clean_sfdc_advertiser_df.merge(clean_sfdc_account_df, how='left', on='sfdc_account_id', suffixes=('_adv', '_acc'))\n",
    "clean_sfdc_adv_account_df = clean_sfdc_adv_account_df[sfdc_adv_account_cols].copy()\n",
    "clean_sfdc_rate_card_df = clean_sfdc_rate_card_df[sfdc_rate_card_cols].copy()\n",
    "clean_sfdc_adv_account_rate_card_df = clean_sfdc_adv_account_df[sfdc_adv_account_cols].merge(clean_sfdc_rate_card_df[sfdc_rate_card_cols], how='left', on='sfdc_rate_card_id', suffixes=('_adv', '_rc')).copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# .columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes_list = ['product_code', 'product_name', 'donovan_agency_product_code', 'description', 'isci', 'project_name', 'advertiser', 'client_code',\n",
    "#                    'cable_estimate', 'spot_estimate', 'campaign', 'audience', 'audience2', 'category', 'comercial_id', 'contour_id', 'creative_offer',\n",
    "#                    'donovan_agency_advertiser_code', 'donovan_agency_estimate_code', 'eid', 'group', 'hd_sd', 'id', 'length', 'lob', 'media_type',\n",
    "#                    'message', 'misc', 'module_code', 'offer', 'offer_2', 'phone_number', 'quality', 'revision', 'show_name', 'slug', 'sport_id',\n",
    "#                    'sport_show_sub_category', 'spot_name', 'tag', 'text', 'title', 'veil_id', 'version_name', 'year']\n",
    "# for attr in attributes_list:\n",
    "#     encodings_df[attr] = encodings_df['attributes'].apply(lambda x: x.get(attr))\n",
    "# # encodings_df['product_code'] = encodings_df['attributes'].apply(lambda x: x.get('product_code'))\n",
    "\n",
    "# Define conditions\n",
    "# Ensure 'description' column does not contain None values\n",
    "# encodings_df['description'] = encodings_df['description'].fillna('')\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     encodings_df['product_code'].notnull(),\n",
    "#     encodings_df['product_code'].isnull() & encodings_df['product_name'].notnull(),\n",
    "#     encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].notnull(),\n",
    "#     encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     encodings_df['product_code'],\n",
    "#     encodings_df['product_name'],\n",
    "#     encodings_df['donovan_agency_product_code'],\n",
    "#     encodings_df['description'].str[26:30].str.strip(),\n",
    "#     encodings_df['description'].str[6:10].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# encodings_df['product_code'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     encodings_df['isci'].notnull(),\n",
    "#     encodings_df['isci'].isnull() & encodings_df['project_name'].notnull(),\n",
    "#     encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     encodings_df['isci'],\n",
    "#     encodings_df['project_name'],\n",
    "#     encodings_df['description'].str[8:18].str.strip(),\n",
    "#     encodings_df['description'].str[18:38].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# encodings_df['isci'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "# # Define conditions\n",
    "# conditions = [\n",
    "#     encodings_df['advertiser'].notnull(),\n",
    "#     encodings_df['advertiser'].isnull() & encodings_df['client_code'].notnull(),\n",
    "#     encodings_df['advertiser'].isnull() & encodings_df['client_code'].isnull() & encodings_df['donovan_agency_advertiser_code'].notnull(),\n",
    "#     encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "#     encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "# ]\n",
    "\n",
    "# # Define corresponding values\n",
    "# choices = [\n",
    "#     encodings_df['advertiser'],\n",
    "#     encodings_df['client_code'],\n",
    "#     encodings_df['donovan_agency_advertiser_code'],\n",
    "#     encodings_df['description'].str[22:26].str.strip(),\n",
    "#     encodings_df['description'].str[2:6].str.strip()\n",
    "# ]\n",
    "\n",
    "# # Apply conditions and choices to create the new column\n",
    "# encodings_df['advertiser'] = np.select(conditions, choices, default=None)\n",
    "# encodings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes_list = ['product_code', 'product_name', 'donovan_agency_product_code', 'description', 'isci', 'project_name', 'advertiser', 'client_code',\n",
    "#                    'cable_estimate', 'spot_estimate', 'campaign', 'audience', 'audience2', 'category', 'comercial_id', 'contour_id', 'creative_offer',\n",
    "#                    'donovan_agency_advertiser_code', 'donovan_agency_estimate_code', 'eid', 'group', 'hd_sd', 'id', 'length', 'lob', 'media_type',\n",
    "#                    'message', 'misc', 'module_code', 'offer', 'offer_2', 'phone_number', 'quality', 'revision', 'show_name', 'slug', 'sport_id',\n",
    "#                    'sport_show_sub_category', 'spot_name', 'tag', 'text', 'title', 'veil_id', 'version_name', 'year']\n",
    "# for attr in attributes_list:\n",
    "#     encodings_df[attr] = encodings_df['attributes'].apply(lambda x: x.get(attr))\n",
    "# encodings_df['product_code'] = encodings_df['attributes'].apply(lambda x: x.get('product_code'))\n",
    "\n",
    "# Define conditions\n",
    "# Ensure 'description' column does not contain None values\n",
    "\n",
    "\n",
    "#  new cell\n",
    "\n",
    "# sfdc_account_df['sfdc_account_id'] = sfdc_account_df['Id']\n",
    "# sfdc_account_df['sfdc_account_name'] = sfdc_account_df['Name']\n",
    "# sfdc_bvs_customer_df['customer_id'] = sfdc_bvs_customer_df['customer_id__c'].astype(int)\n",
    "# sfdc_bvs_customer_df['sfdc_account_id'] = sfdc_bvs_customer_df['Account__c']\n",
    "account_cols = ['sfdc_account_id', 'sfdc_account_name']\n",
    "customer_cols = ['customer_id', 'sfdc_account_id']\n",
    "clean_sfdc_cust_account_df = clean_sfdc_account_df[account_cols].merge(clean_sfdc_bvs_customer_df[customer_cols], on='sfdc_account_id', how='inner', suffixes=('_sfdc_account', '_sfdc_customer'))\n",
    "\n",
    "clean_sfdc_cust_account_df\n",
    "sfdc_bvs_cust_account_df = clean_sfdc_cust_account_df.merge(processed_customers_df, left_on='customer_id', right_on='customer_id', how='inner', suffixes=('_sfdc', '_avs'))\n",
    "\n",
    "# new cell\n",
    "\n",
    "core_functions.rename_columns(processed_encoder_groups_df, 'encoder_group_')\n",
    "core_functions.rename_columns(processed_encoders_df, 'encoder_')\n",
    "core_functions.rename_columns(processed_formats_df, 'format_')\n",
    "core_functions.rename_columns(processed_customers_df, 'customer_')\n",
    "core_functions.rename_columns(processed_profiles_df, 'profile_')\n",
    "core_functions.rename_columns(processed_aeismaps_df, 'aeis_')\n",
    "\n",
    "# clean_processed_encodings_df\n",
    "\n",
    "# encodings_df['encoding_id'] = encodings_df['encoding_id'].astype(int)\n",
    "encoders_groups_df = processed_encodings_df.merge(processed_encoder_groups_df, left_on='encoder_group_id', right_on='encoder_group_id', how='left').drop_duplicates(subset=['encoding_id']).copy()\n",
    "encoders_groups_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoders_groups_df.drop_duplicates(subset=['encoding_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_groups_df[encoders_groups_df['encoding_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_encodings_df.head()\n",
    "len(processed_encodings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders_groups_df\n",
    "cols_in_processed_encodings_df = processed_encodings_df.columns.to_list()\n",
    "cols_in_processed_encodings_df = list(set(cols_in_processed_encodings_df) - {'encoding_id'})\n",
    "for col in cols_in_processed_encodings_df:\n",
    "    if col in encoders_groups_df.columns:\n",
    "        encoders_groups_df.drop(col, axis=1, inplace=True)\n",
    "encoders_groups_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoders_groups_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encodings_encoders_df = processed_encodings_df.merge(encoders_groups_df, left_on='encoding_id', right_on='encoding_id', how='left', suffixes=('', '_dupe'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_encoders_df.head()\n",
    "len(encodings_encoders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_aeismaps_df.sort_values(by=['aeis__encoding_id', 'aeis_id', ], inplace=True)\n",
    "\n",
    "# processed_aeismaps_df = processed_aeismaps_df.loc[(processed_aeismaps_df['aeis_id'].fillna(0.0).astype(int) > 0) & (aeismaps_df['aeis__encoding_id'].fillna(0.0).astype(int) > 0)]\n",
    "processed_aeismaps_df.drop_duplicates(subset=('aeis__encoding_id' ), inplace=True)\n",
    "processed_aeismaps_df\n",
    "print(len(processed_aeismaps_df))\n",
    "\n",
    "encodings_aeis_df = encodings_encoders_df.merge(processed_aeismaps_df, left_on='encoding_id', right_on='aeis__encoding_id', how='left')\n",
    "encodings_aeis_df\n",
    "\n",
    "# processed_formats_df['format__customer_id'] = formats_df['format__customer_id'].astype(int)\n",
    "# formats_df['format__profile_id'] = formats_df['format__profile_id'].astype(int)\n",
    "# sfdc_bvs_cust_account_df['customer_id'] = sfdc_bvs_cust_account_df['customer_id'].astype(int)\n",
    "formats_customers_df = processed_formats_df.merge(sfdc_bvs_cust_account_df, left_on='format__customer_id', right_on='customer_id', how='left')\n",
    "formats_customers_df\n",
    "\n",
    "formats_customers_profiles_df = formats_customers_df.merge(processed_profiles_df, left_on='format__profile_id', right_on='profile_id', how='left')\n",
    "formats_customers_profiles_df\n",
    "\n",
    "encodings_bvs_df = encodings_aeis_df.merge(formats_customers_profiles_df, on='format_id',  how='left', suffixes=('', '_drop'))\n",
    "for col in encodings_bvs_df.columns:\n",
    "    if col.endswith('_drop'):\n",
    "        encodings_bvs_df.drop(columns=col, inplace=True)\n",
    "encodings_bvs_df\n",
    "\n",
    "encodings_bvs_df['ad_prod_campaign'] = None\n",
    "encodings_bvs_df['advertiser'] = encodings_bvs_df['advertiser'].fillna('')\n",
    "encodings_bvs_df['product_code'] = encodings_bvs_df['product_code'].fillna('')\n",
    "encodings_bvs_df['campaign'] = encodings_bvs_df['attributes_campaign'].fillna('')\n",
    "\n",
    "# Update ad_prod_campaign\n",
    "encodings_bvs_df['ad_prod_campaign'] = encodings_bvs_df.apply(\n",
    "    lambda row: f\"{row['advertiser'].strip()}-{row['product_code'].strip()}-{row['campaign'].strip()}\".replace(' ', '_') if pd.isnull(row['ad_prod_campaign']) else row['ad_prod_campaign'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# new cell\n",
    "\n",
    "encodings_bvs_df.sort_values(by=[ 'encoding_id', 'last_updated','sfdc_account_id', 'format_id', 'profile_id', 'customer_id'], inplace=True)\n",
    "\n",
    "# new cell\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_bvs_df.drop_duplicates(subset=['encoding_id'], keep='last', inplace=True)\n",
    "encodings_bvs_df.head()\n",
    "\n",
    "len(encodings_bvs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrames\n",
    "# encodings_bvs_df = pd.DataFrame(...)\n",
    "# sfdc_advertiser_df = pd.DataFrame(...)\n",
    "\n",
    "processed_formats_df.dtypes\n",
    "\n",
    "\n",
    "# # Define a function to perform the updates\n",
    "# def update_encodings_bvs_df(encodings_bvs_df, sfdc_advertiser_df):\n",
    "#     # First update\n",
    "#     mask = encodings_bvs_df['ad_prod_campaign'].isnull()\n",
    "#     encodings_bvs_df.loc[mask, 'ad_prod_campaign'] = encodings_bvs_df[mask].apply(\n",
    "#         lambda row: f\"{row['advertiser'].strip()}-{row['product_code'].strip()}-{row['campaign'].strip()}\".replace(' ', '_'),\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     # Define a function to perform the updates based on conditions\n",
    "#     def update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, left_on, right_on, match_type):\n",
    "#         merged_df = encodings_bvs_df.merge(sfdc_advertiser_df, how='left', left_on=left_on, right_on=right_on)\n",
    "#         mask = (merged_df['sfdc_advertiser_id'].isnull()) & (merged_df['Encoding_Format_ID__c'].notnull()) & (merged_df['format_id'] == merged_df['Encoding_Format_ID__c']) & (merged_df['Match_Type__c'] == match_type)\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_id'] = merged_df.loc[mask, 'Id']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_name'] = merged_df.loc[mask, 'Name']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_match_type'] = merged_df.loc[mask, 'Match_Type__c']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_rate_card_id'] = merged_df.loc[mask, 'Related_Rate_Card__c']\n",
    "#         encodings_bvs_df.loc[mask, 'advertiser_updated'] = pd.Timestamp.now()\n",
    "\n",
    "#     # Apply updates based on different conditions\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code_multiple')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code_ignore_format')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'advertiser', 'Enc_Advertiser__c', 'encoding_advertiser')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'advertiser', 'Enc_Advertiser__c', 'encoding_advertiser_ignore_format')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'format_id', 'Encoding_Format_ID__c', 'encoding_format')\n",
    "\n",
    "# # Call the function to update the DataFrame\n",
    "# update_encodings_bvs_df(encodings_bvs_df, sfdc_advertiser_df)\n",
    "\n",
    "# print(encodings_bvs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting with {len(encodings_bvs_df)} rows\")\n",
    "accounted_for = 0\n",
    "print(f\"Accounted for {accounted_for} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sfdc_advertiser_df['match_type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting with {len(encodings_bvs_df)} rows\")\n",
    "accounted_for = 0\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoding_product_code_multiple'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoding_product_code_multiple_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_product_code_multiple_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoding_product_code'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoding_product_code_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_product_code_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoding_advertiser'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoding_advertiser_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_advertiser_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoding_advertiser_ignore_format'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoding_advertiser_ignore_format_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_advertiser_ignore_format_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoding_format'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoding_format_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_format_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "print(\"finished normal matches\")\n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'encoder_group'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "encoder_group_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoder_group_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'] == 'Clone'\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "clone_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(clone_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "mask = clean_sfdc_advertiser_df['match_type'].isna()\n",
    "print(len(clean_sfdc_advertiser_df.loc[mask]))\n",
    "null_match_sfdc_advertiser_df = clean_sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(null_match_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "print(f\"Started with {len(clean_sfdc_advertiser_df)} rows and accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# array(['encoding_format', 'encoder_group', 'Clone',\n",
    "    #    'encoding_product_code_multiple', None, 'encoding_advertiser',\n",
    "    #    'encoding_product_code', 'encoding_advertiser_ignore_format'],\n",
    "    #   dtype=object)\n",
    "# 14327 total\n",
    "# encoding_format: 14174\n",
    "# encoder_group: 32\n",
    "# Clone: 2\n",
    "# encoding_product_code_multiple: 17\n",
    "# encoding_advertiser: 7\n",
    "# encoding_product_code: 37\n",
    "# encoding_advertiser_ignore_format: 45\n",
    "#  null: 13\n",
    "print(14327 - 14174 - 32 - 2 - 17 - 7 - 37 - 45 - 13)\n",
    "# clean_sfdc_advertiser_df.loc[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles_df.loc[profiles_df['profile__default_asset_code'] != 'isci']\n",
    "\n",
    "# expanded_df = profiles_df['profile__attributes'].apply(pd.Series)\n",
    "\n",
    "# # Combine the original DataFrame with the expanded DataFrame\n",
    "# result_df = pd.concat([profiles_df, expanded_df], axis=1)\n",
    "# core_functions.show_more_dataframe()\n",
    "# result_df\n",
    "        # CASE WHEN (e.attributes.product_code is NOT NULL) THEN e.attributes.product_code\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NOT NULL) THEN e.attributes.product_name\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NOT NULL) THEN e.attributes.donovan_agency_product_code\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NULL and e.attributes.description is not null and length(e.attributes.description) > 10 and (e.attributes.description not like 'TV%' or e.attributes.description not like 'RA%')) THEN trim(substring(e.attributes.description, 27,4))\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NULL and e.attributes.description is not null and length(e.attributes.description) > 10 and (e.attributes.description  like 'TV%' or e.attributes.description  like 'RA%')) THEN trim(substring(e.attributes.description, 7,4))\n",
    "        # ELSE NULL END AS product_code,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_bvs_encoding_product_code_multiple_sfdc_advertiser_df = encodings_bvs_df.merge(encoding_product_code_multiple_sfdc_advertiser_df, left_on='format_id', right_on='encoding_format_id', how='left', suffixes=('', '_encoding_format')).dropna(subset=['sfdc_advertiser_id'])\n",
    "print(f\"Starting with {len(clean_sfdc_advertiser_df)} rows\")\n",
    "print(f\"Accounted for {len(encoding_product_code_multiple_sfdc_advertiser_df)} rows\")\n",
    "# [\"ALDR\", \"ALGM\", \"ALHP\"]\n",
    "processed = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "encoding_product_code_multiple_sfdc_advertiser_df['product_code_list_list'] = encoding_product_code_multiple_sfdc_advertiser_df['product_code_list'].apply(lambda x: x.split(','))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# Filter the main DataFrame to include only relevant sfdc_account_ids\n",
    "meta_df = encoding_product_code_multiple_sfdc_advertiser_df\n",
    "df_name = 'encoding_product_code_multiple_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "    print(f\"Processing {df_name}...\")\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['product_code'].fillna('', inplace=True)\n",
    "    # working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "\n",
    "    # Explode product_code_list_list into multiple rows\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "    encoding_expanded_df = encoding_expanded_df.explode('product_code_list_list')\n",
    "    encoding_expanded_df['product_code_list_list'] = encoding_expanded_df['product_code_list_list'].str.replace('\"', '').copy()\n",
    "    encoding_expanded_df['encoding_format_id'] = encoding_expanded_df['encoding_format_id'].astype(int)\n",
    "    encoding_expanded_df[['product_code_list_list', 'encoding_format_id', 'sfdc_advertiser_id']]\n",
    "    # encoding_expanded_master_df = encoding_expanded_df.sort_values(by=['encoding_format_id', 'product_code_list_list'], inplace=True)\n",
    "    encoding_expanded_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df.drop_duplicates(subset=['encoding_format_id', 'product_code_list_list'], keep='first', inplace=True)\n",
    "    # encoding_expanded_master_df['encoding_format_id'].fillna('0', inplace=True)\n",
    "    # encoding_expanded_master_df['product_code_list_list'].fillna('', inplace=True)\n",
    "    # encoding_expanded_master2_df = encoding_expanded_master_df.drop_duplicates(subset=['encoding_format_id', 'product_code_list_list'], keep='first')\n",
    "    # len(encoding_expanded_master2_df)\n",
    "    working_df['format_id'] = working_df['format_id'].astype(int)\n",
    "    # Perform the merge based on format_id and product_code\n",
    "    merged_df = working_df.merge(\n",
    "        encoding_expanded_df,\n",
    "        left_on=['format_id', 'product_code'],\n",
    "        right_on=['encoding_format_id', 'product_code_list_list'],\n",
    "        how='left', suffixes=('', '_encoding_format')\n",
    "    )\n",
    "    merged_df = merged_df.dropna(subset=['sfdc_advertiser_id'])\n",
    "    merged_df['encoding_id'] = merged_df['encoding_id'].astype(int)\n",
    "    working_df['encoding_id'] = working_df['encoding_id'].astype(int)\n",
    "    merged_df[['encoding_id','sfdc_account_id']]\n",
    "    print(f\"Starting with {len(working_df)} rows\")\n",
    "    working_df2 = working_df.merge(merged_df[['encoding_id', 'sfdc_advertiser_id']], on='encoding_id', how='left',)\n",
    "    print(f\"Accounted for {len(working_df2)} rows\")\n",
    "    working_df2.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    # # Assign the advertiser ID to the original DataFrame\n",
    "    # working_df['sfdc_advertiser_id'] = merged_df['sfdc_advertiser_id']\n",
    "    # # working_df.dropna(subset=['sfdc_advertiser_id'])\n",
    "    # working_df\n",
    "    working_df2.columns.tolist()\n",
    "\n",
    "    new_encodings_bvs_df = pd.DataFrame(columns=working_df2.columns)\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, working_df2], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "    processed.append(df_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "meta_df = encoding_product_code_sfdc_advertiser_df\n",
    "df_name = 'encoding_product_code_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['product_code'].fillna('', inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    # working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "    encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id', 'encoding_product_code', 'product_code']]\n",
    "    encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "    encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "    encoding_expanded_df.rename(columns={'enc_product_code': 'product_code'}, inplace=True)\n",
    "    encoding_expanded_df\n",
    "    encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "    encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id', 'product_code']].copy()\n",
    "    encoding_expanded_slim_df\n",
    "\n",
    "    merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id', 'product_code'], how='left')\n",
    "    merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    merged_df\n",
    "    new_encodings_bvs_df\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "\n",
    "    processed.append(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# encoding_product_code_ignore_format\n",
    "meta_df =encoding_advertiser_ignore_format_sfdc_advertiser_df\n",
    "df_name = 'encoding_advertiser_ignore_format_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['product_code'].fillna('', inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "    encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id',  'encoding_product_code', 'product_code']]\n",
    "    # encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "    encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "    encoding_expanded_df.rename(columns={'enc_product_code': 'product_code'}, inplace=True)\n",
    "    encoding_expanded_df\n",
    "    encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "    encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id',  'product_code']].copy()\n",
    "    encoding_expanded_slim_df\n",
    "\n",
    "    merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id',  'product_code'], how='left')\n",
    "    merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    merged_df\n",
    "    new_encodings_bvs_df\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "\n",
    "    processed.append(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# encoding_advertiser\n",
    "meta_df = encoding_advertiser_sfdc_advertiser_df\n",
    "df_name = 'encoding_advertiser_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['advertiser'].fillna('', inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "    encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id', 'enc_advertiser']]\n",
    "    encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "    encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "    encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "    encoding_expanded_df\n",
    "    encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "    encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id', 'advertiser']].copy()\n",
    "    encoding_expanded_slim_df\n",
    "\n",
    "    merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id', 'advertiser'], how='left')\n",
    "    merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    merged_df\n",
    "    new_encodings_bvs_df\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "\n",
    "    processed.append(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# encoding_advertiser_ignore_format\n",
    "meta_df = encoding_advertiser_ignore_format_sfdc_advertiser_df\n",
    "df_name = 'encoding_advertiser_ignore_format_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['advertiser'].fillna('', inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "    encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id',  'enc_advertiser']]\n",
    "    # encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "    encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "    encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "    encoding_expanded_df\n",
    "    encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "    encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id',  'advertiser']].copy()\n",
    "    encoding_expanded_slim_df\n",
    "\n",
    "    merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'advertiser'], how='left')\n",
    "    merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    merged_df\n",
    "    new_encodings_bvs_df\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "\n",
    "    processed.append(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# encoding_format\n",
    "meta_df = encoding_format_sfdc_advertiser_df\n",
    "df_name = 'encoding_format_sfdc_advertiser_df'\n",
    "if df_name in processed:\n",
    "    print(f\"Already processed {df_name}\")\n",
    "else:\n",
    "    sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "    working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "    # Ensure 'product_code' column is filled with empty strings for null values\n",
    "    working_df['advertiser'].fillna('', inplace=True)\n",
    "    if 'sfdc_advertiser_id' in working_df.columns:\n",
    "        working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "    encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "    encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id']]\n",
    "    encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "    # encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "    # encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "    encoding_expanded_df\n",
    "    encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "    encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id']].copy()\n",
    "    encoding_expanded_slim_df\n",
    "\n",
    "    merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id'], how='left')\n",
    "    merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "    merged_df\n",
    "    new_encodings_bvs_df\n",
    "    new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "    new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "    len(new_encodings_bvs_df)\n",
    "    # 1686537\n",
    "\n",
    "    processed.append(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "new_encodings_bvs_df.sort_values(by=['sfdc_account_id', 'sfdc_advertiser_id','format_id', 'profile_id', 'customer_id', 'encoding_id'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# new_encodings_bvs_merge_df = new_encodings_bvs_df[['encoding_id', 'sfdc_advertiser_id']].drop_\n",
    "# new_encodings_bvs_merge_df\n",
    "# encodings_bvs_df_to_write = encodings_bvs_df.merge(new_encodings_bvs_merge_df, on='encoding_id', how='left')\n",
    "# encodings_bvs_df_to_write\n",
    "len(encodings_bvs_df)\n",
    "len(encodings_bvs_df[~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))]) + len(new_encodings_bvs_df)\n",
    "encodings_bvs_df['sfdc_advertiser_id'] = ''\n",
    "# 1686537\n",
    "# 1686866\n",
    "encodings_bvs_df_to_write = pd.concat([encodings_bvs_df[~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))], new_encodings_bvs_df], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# encodings_bvs_df_to_write.sort_values(by=['sfdc_account_id'], inplace=True)\n",
    "billing_last_updated = pd.Timestamp.utcnow()\n",
    "encodings_bvs_df_to_write['billing_last_updated'] = billing_last_updated\n",
    "billing_last_audit_id = core_functions.generate_uuid()\n",
    "encodings_bvs_df_to_write['billing_last_audit_id'] = billing_last_audit_id\n",
    "# encodings_bvs_df_to_write\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# pd.options.display.max_rows = None\n",
    "# int_cols = ['encoding_id','encoder_group_id']\n",
    "# # encodings_bvs_df_to_write[]\n",
    "# # print(encodings_bvs_df_to_write.dtypes)\n",
    "# # encodings_bvs_df_to_write['aeis_id'].isna()\n",
    "# mask = encodings_bvs_df_to_write['aeis_id'].isna()\n",
    "# encodings_bvs_df_to_write[mask,[['encoding_id','encoded_timestamp']]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_final_cols = ['encoding_id',\n",
    " 'format_id',\n",
    " 'encoder_group_id',\n",
    " 'encoded_timestamp',\n",
    " 'clone_of',\n",
    " 'status',\n",
    " 'last_updated',\n",
    " 'last_audit_id',\n",
    " 'encoder_id',\n",
    " 'detection_end_date',\n",
    " 'encoded_timestamp_epoch',\n",
    " 'attributes_advertiser',\n",
    " 'attributes_audience',\n",
    " 'attributes_audience_2',\n",
    " 'attributes_cable_estimate',\n",
    " 'attributes_campaign',\n",
    " 'attributes_category',\n",
    " 'attributes_client_code',\n",
    " 'attributes_commercial_id',\n",
    " 'attributes_contour_id',\n",
    " 'attributes_creative_offer',\n",
    " 'attributes_description',\n",
    " 'attributes_donovan_agency_advertiser_code',\n",
    " 'attributes_donovan_agency_estimate_code',\n",
    " 'attributes_donovan_agency_product_code',\n",
    " 'attributes_eid',\n",
    " 'attributes_group',\n",
    " 'attributes_hd_sd',\n",
    " 'attributes_id',\n",
    " 'attributes_isci',\n",
    " 'length_in_seconds',\n",
    " 'attributes_length',\n",
    " 'attributes_lob',\n",
    " 'attributes_media_type',\n",
    " 'attributes_message',\n",
    " 'attributes_misc',\n",
    " 'attributes_module_code',\n",
    " 'attributes_offer',\n",
    " 'attributes_offer_2',\n",
    " 'attributes_phone_number',\n",
    " 'attributes_product_code',\n",
    " 'attributes_product_name',\n",
    " 'attributes_project_name',\n",
    " 'attributes_quality',\n",
    " 'attributes_revision',\n",
    " 'attributes_show_name',\n",
    " 'attributes_slug',\n",
    " 'attributes_sport_id',\n",
    " 'attributes_sport_show_sub_category',\n",
    " 'attributes_spot_estimate',\n",
    " 'attributes_spot_name',\n",
    " 'attributes_tag',\n",
    " 'attributes_text',\n",
    " 'attributes_title',\n",
    " 'attributes_veil_id',\n",
    " 'attributes_version_name',\n",
    " 'attributes_year',\n",
    " 'product_code',\n",
    " 'isci',\n",
    " 'advertiser',\n",
    " 'encoder_group_name',\n",
    " 'encoder_group__deleted',\n",
    " 'encoder_group__last_audit_id',\n",
    " 'encoder_group__last_updated',\n",
    " 'aeis_id',\n",
    " 'aeis__encoding_id',\n",
    " 'aeis__encoding_offset',\n",
    " 'aeis__last_updated',\n",
    " 'aeis__last_audit_id',\n",
    " 'format_name',\n",
    " 'format__profile_id',\n",
    " 'format__customer_id',\n",
    " 'format__report_breakup',\n",
    " 'format__deleted',\n",
    " 'format__last_updated',\n",
    " 'format__last_audit_id',\n",
    " 'sfdc_account_id',\n",
    " 'sfdc_account_name',\n",
    " 'customer_id',\n",
    " 'account_id',\n",
    " 'contract_item',\n",
    " 'customer_name',\n",
    " 'contract_number',\n",
    " 'sales_person_code',\n",
    " 'deleted',\n",
    " 'profile_id',\n",
    " 'profile_name',\n",
    " 'profile__deleted',\n",
    " 'profile__default_asset_code',\n",
    " 'profile__last_updated',\n",
    " 'profile__last_audit_id',\n",
    " 'ad_prod_campaign',\n",
    " 'campaign',\n",
    " 'sfdc_advertiser_id',\n",
    " 'billing_last_updated',\n",
    " 'billing_last_audit_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = ['encoding_id','format_id','encoder_group_id','clone_of','encoder_id','encoded_timestamp_epoch', 'length_in_seconds', 'aeis_id','aeis__encoding_id','aeis__encoding_offset','format__profile_id','format__customer_id','format__last_updated','customer_id','account_id','contract_item','contract_number']\n",
    "date_cols = ['encoded_timestamp', 'last_updated','detection_end_date','encoder_group__last_updated','aeis__last_updated','profile__last_updated','billing_last_updated']\n",
    "drop_cols = ['attributes','profile__attributes']\n",
    "bool_cols = ['encoder_group__deleted','format__deleted','deleted']\n",
    "for col in encodings_bvs_df_to_write.columns:\n",
    "    if col in encodings_bvs_df_to_write.columns and col not in valid_final_cols:\n",
    "        encodings_bvs_df_to_write.drop(columns=col, inplace=True)\n",
    "    if col in int_cols:\n",
    "        encodings_bvs_df_to_write[col] = encodings_bvs_df_to_write[col].fillna(-1).astype(int)\n",
    "    if col in date_cols:\n",
    "        encodings_bvs_df_to_write[col] = pd.to_datetime(encodings_bvs_df_to_write[col], errors='coerce', utc=True)\n",
    "    if col in drop_cols and col in encodings_bvs_df_to_write.columns:\n",
    "        encodings_bvs_df_to_write.drop(columns=col, inplace=True)\n",
    "    if col in bool_cols:\n",
    "        encodings_bvs_df_to_write[col] = encodings_bvs_df_to_write[col].fillna(False).astype(bool)\n",
    "    if col in valid_final_cols and col not in encodings_bvs_df_to_write.columns:\n",
    "        encodings_bvs_df_to_write[col] = ''\n",
    "    if col in valid_final_cols and col not in int_cols and col not in date_cols and col not in bool_cols:\n",
    "        encodings_bvs_df_to_write[col] = encodings_bvs_df_to_write[col].fillna('').astype(str)\n",
    "for col in encodings_bvs_df_to_write.columns:\n",
    "    print(f\"{col}: type: {encodings_bvs_df_to_write[col].dtype}\")\n",
    "# encodings_bvs_df_to_write.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new cell\n",
    "\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "process_df = encodings_bvs_df_to_write.copy()\n",
    "\n",
    "# nested_columns = ['attributes']\n",
    "# for col in nested_columns:\n",
    "#     process_df[col] = process_df[col].apply(lambda x: json.dumps(x) if pd.notna(x) else '')\n",
    "    \n",
    "# def parse_iso_with_timezone(ts):\n",
    "#     # Replace timezone colon\n",
    "#     ts = ts.replace(\":\", \"\", 1) if \"+\" in ts or \"-\" in ts else ts\n",
    "#     return datetime.strptime(ts, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "# # parsed_timestamps = [parse_iso_with_timezone(ts) for ts in process_df['encoded_timestamp'] ]\n",
    "# process_df['encoded_timestamp'] = process_df['encoded_timestamp'].apply(parse_iso_with_timezone)\n",
    "\n",
    "# print(parsed_timestamps)\n",
    "# process_df['encoded_timestamp'] = pd.to_datetime(process_df['encoded_timestamp'])\n",
    "# process_df = core_functions.convert_to_string_except_exclusions(process_df, exclude_columns=['encoded_timestamp', 'encoding_id', 'format_id','customer_id', 'profile_id', 'billing_last_updated', 'deleted', 'profile_deleted'])\n",
    "# process_df.drop(columns=['attributes'], inplace=True)\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "n90_storage_options = config.get('N90_GCS_STORAGE_OPTIONS')\n",
    "\n",
    "veil_billing_bucket = config.get('veil_billing').get('billing_gcs_bucket_id')\n",
    "process_df['encoded_timestamp']\n",
    "# process_df['profile__attributes']\n",
    "n90_bucket = 'n90_veil_partner'\n",
    "veil_output_prefix = 'encodings'\n",
    "n90_output_prefix = 'advocado-looker/avs_prod/encodings'\n",
    "partition_cols = ['sfdc_account_id']\n",
    "core_functions.write_hive_partitioned_parquet(process_df, veil_billing_bucket, veil_output_prefix, partition_cols, veil_storage_options)\n",
    "print(f\"Finished writing to {veil_billing_bucket}/{veil_output_prefix}\")\n",
    "core_functions.write_hive_partitioned_parquet(process_df, n90_bucket, n90_output_prefix, partition_cols, n90_storage_options)\n",
    "print(f\"Finished writing to {n90_bucket}/{n90_output_prefix}\")\n",
    "\n",
    "# new cell\n",
    "\n",
    "print(encodings_bvs_df_to_write.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
