{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import functions.core_functions as core_functions\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe.utils import assert_eq\n",
    "# import dask_cudf as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_gbq\n",
    "\n",
    "dask.config.set({\"dataframe.backend\": \"cudf\"})\n",
    "\n",
    "\n",
    "\n",
    "importlib.reload(core_functions)\n",
    "\n",
    "\n",
    "resp = {}\n",
    "resp = core_functions.initialize_clients()\n",
    "\n",
    "config = resp.get('config')\n",
    "bigquery_client = resp.get('clients').get('bigquery_client')\n",
    "storage_client = resp.get('clients').get('storage_client')\n",
    "sf_client = resp.get('clients').get('sf_client')\n",
    "veil_billing = resp.get('config').get('veil_billing')\n",
    "veil_vars = resp.get('config').get('veil_billing').get('vars')\n",
    "print(veil_billing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_table = 'encodings'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "encodings_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'encoders'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "encoders_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'encoder_groups'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "encoder_groups_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "\n",
    "target_table = 'formats'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "formats_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'customers'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "customers_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'profiles'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "profiles_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'aeismaps'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('avs_project_id')}.{veil_billing.get('avs_dataset_id')}.{target_table}\"\"\"\n",
    "aeismaps_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "\n",
    "target_table = 'sfdc_bvs_customer__c_obj'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "sfdc_bvs_customer_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'sfdc_bvs_format__c_obj'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "sfdc_bvs_format_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'sfdc_account_obj'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "sfdc_account_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'sfdc_advertiser__c_obj'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "sfdc_advertiser_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "target_table = 'sfdc_rate_card__c_obj'\n",
    "fetch_sql = f\"\"\"\n",
    "SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "sfdc_rate_card_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n",
    "# target_table = 'sfdc_rate_card__c_obj'\n",
    "# fetch_sql = f\"\"\"\n",
    "# SELECT * from {veil_billing.get('billing_project_id')}.{veil_billing.get('billing_dataset_id')}.{target_table}\"\"\"\n",
    "# sfdc_rate_card_df = core_functions.fetch_gbq_data(fetch_sql, bigquery_client)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_list = ['product_code', 'product_name', 'donovan_agency_product_code', 'description', 'isci', 'project_name', 'advertiser', 'client_code',\n",
    "                   'cable_estimate', 'spot_estimate', 'campaign', 'audience', 'audience2', 'category', 'comercial_id', 'contour_id', 'creative_offer',\n",
    "                   'donovan_agency_advertiser_code', 'donovan_agency_estimate_code', 'eid', 'group', 'hd_sd', 'id', 'length', 'lob', 'media_type',\n",
    "                   'message', 'misc', 'module_code', 'offer', 'offer_2', 'phone_number', 'quality', 'revision', 'show_name', 'slug', 'sport_id',\n",
    "                   'sport_show_sub_category', 'spot_name', 'tag', 'text', 'title', 'veil_id', 'version_name', 'year']\n",
    "for attr in attributes_list:\n",
    "    encodings_df[attr] = encodings_df['attributes'].apply(lambda x: x.get(attr))\n",
    "# encodings_df['product_code'] = encodings_df['attributes'].apply(lambda x: x.get('product_code'))\n",
    "\n",
    "# Define conditions\n",
    "# Ensure 'description' column does not contain None values\n",
    "encodings_df['description'] = encodings_df['description'].fillna('')\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['product_code'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['product_code'],\n",
    "    encodings_df['product_name'],\n",
    "    encodings_df['donovan_agency_product_code'],\n",
    "    encodings_df['description'].str[26:30].str.strip(),\n",
    "    encodings_df['description'].str[6:10].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['product_code'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['isci'].notnull(),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].notnull(),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['isci'],\n",
    "    encodings_df['project_name'],\n",
    "    encodings_df['description'].str[8:18].str.strip(),\n",
    "    encodings_df['description'].str[18:38].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['isci'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['advertiser'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['client_code'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['client_code'].isnull() & encodings_df['donovan_agency_advertiser_code'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['advertiser'],\n",
    "    encodings_df['client_code'],\n",
    "    encodings_df['donovan_agency_advertiser_code'],\n",
    "    encodings_df['description'].str[22:26].str.strip(),\n",
    "    encodings_df['description'].str[2:6].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['advertiser'] = np.select(conditions, choices, default=None)\n",
    "encodings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdc_adv_account_cols = [\n",
    " 'recordtypeid_adv',\n",
    " 'createddate_adv',\n",
    " 'createdbyid_adv',\n",
    " 'lastmodifieddate_adv',\n",
    " 'lastmodifiedbyid_adv',\n",
    " 'systemmodstamp_adv',\n",
    " 'lastactivitydate_adv',\n",
    " 'lastvieweddate_adv',\n",
    " 'lastreferenceddate_adv',\n",
    " 'billing_frequency',\n",
    " 'notes',\n",
    " 'po_number',\n",
    " 'po_required',\n",
    " 'term_date_end',\n",
    " 'term_date_start',\n",
    " 'active_po',\n",
    " 'product_code',\n",
    " 'status',\n",
    " 'advertiser_name_location',\n",
    " 'adv_acct',\n",
    " 'format_code',\n",
    " 'invoice_format',\n",
    " 'cloned_advertiser',\n",
    " 'bvs_format_id',\n",
    " 'match_type',\n",
    " 'purchase_order_record',\n",
    " 'radio_rate_card',\n",
    " 'radio_advertiser',\n",
    " 'product_code_list',\n",
    " 'encoding_advertiser',\n",
    " 'encoding_module_code',\n",
    " 'encoding_product_code',\n",
    " 'encoder_group',\n",
    " 'encoding_format',\n",
    " 'bvs_customer_id',\n",
    " 'encoding_format_id',\n",
    " 'encoding_format_is_deleted',\n",
    " 'enc_product_code',\n",
    " 'enc_advertiser',\n",
    " 'encoder_group_id',\n",
    " 'dish_included',\n",
    " 'directv_included',\n",
    " 'format_profile',\n",
    " 'sfdc_advertiser_id',\n",
    " 'sfdc_advertiser_name',\n",
    " 'sfdc_account_id',\n",
    " 'sfdc_rate_card_id',\n",
    " 'parentid',\n",
    " 'website',\n",
    " 'industry',\n",
    " 'annualrevenue',\n",
    " 'numberofemployees',\n",
    " 'description',\n",
    " 'ownerid',\n",
    " 'account_service_rep',\n",
    " 'customer_type',\n",
    " 'original_contract_date',\n",
    " 'current_term_start',\n",
    " 'evergreen',\n",
    " 'contract_term_length_yrs',\n",
    " 'adhoc_billing',\n",
    " 'contract_expired',\n",
    " 'annual_price_increase_per_contract',\n",
    " 'price_increase_last_applied',\n",
    " 'contract_missing',\n",
    " 'account_notes_questions',\n",
    " 'inactive_customer',\n",
    " 'inactive_customer_date',\n",
    " 'renewal_inactive_notes',\n",
    " 'renewal_in_next_90_days',\n",
    " 'delivered_to_ftp',\n",
    " 'net_app_access',\n",
    " 'encoder',\n",
    " 'currency',\n",
    " 'brand_id',\n",
    " 'group_by_device',\n",
    " 'encoder_id',\n",
    " 'maxio_customer',\n",
    " 'purchase_order_required',\n",
    " 'quarterly_bulk_changes',\n",
    " 'net_terms',\n",
    " 'contract_type',\n",
    " 'po_req',\n",
    " 'sfdc_account_name']\n",
    "\n",
    "sfdc_rate_card_cols = [\n",
    " 'sfdc_rate_card_id',\n",
    " 'isdeleted',\n",
    " 'rate_card_name',\n",
    " 'recordtypeid',\n",
    " 'createddate',\n",
    " 'createdbyid',\n",
    " 'lastmodifieddate',\n",
    " 'lastmodifiedbyid',\n",
    " 'systemmodstamp',\n",
    " 'tier_2_rate',\n",
    " 'tier_2_start',\n",
    " 'tier_1_rate',\n",
    " 'tier_4_rate',\n",
    " 'tier_5_start',\n",
    " 'monthly_minmax',\n",
    " 'tier_5_rate',\n",
    " 'tier_5_label',\n",
    " 'tier_3_start',\n",
    " 'business_type',\n",
    " 'tier_2_label',\n",
    " 'cable_rate',\n",
    " 'tier_3_rate',\n",
    " 'currency',\n",
    " 'spot_rate',\n",
    " 'tier_4_label',\n",
    " 'billing_type',\n",
    " 'tier_1_label',\n",
    " 'canadian_tv_rate',\n",
    " 'rate_card_type',\n",
    " 'broadcast_network_rate',\n",
    " 'usage_included_in_minmax',\n",
    " 'description',\n",
    " 'hispanic_tv_rate',\n",
    " 'tier_1_start',\n",
    " 'media',\n",
    " 'tier_4_start',\n",
    " 'tier_3_label',\n",
    " 'default_rate_card',\n",
    " 'min_max_label',\n",
    " 'min_max_type',\n",
    " 'account',\n",
    " 'bvs_name',\n",
    " 'pricing_dict',\n",
    " 'direct_tv_dish',\n",
    " 'min_max_applied_at',\n",
    " 'mediaocean_formatting',\n",
    " 'sfdc_product_id',\n",
    " 'sfdc_productcode',\n",
    " 'start_date',\n",
    " 'diginet_handling',\n",
    " 'no_spot',\n",
    " 'rate_currency',\n",
    " 'always_bill_min',\n",
    " 'no_of_tiers',\n",
    " 'notes',\n",
    " 'onboarding_fee',\n",
    " 'seasonal_only',\n",
    " 'expired',\n",
    " 'detection_count_by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sfdc_account_df.columns.tolist()\n",
    "for col in sfdc_advertiser_df.columns:\n",
    "    new_col = col.replace('__c', '').lower()\n",
    "    sfdc_advertiser_df.rename(columns={col: new_col}, inplace=True)\n",
    "    if new_col == 'id':\n",
    "        sfdc_advertiser_df.rename(columns={new_col: 'sfdc_advertiser_id'}, inplace=True)\n",
    "    if new_col == 'name':\n",
    "        sfdc_advertiser_df.rename(columns={new_col: 'sfdc_advertiser_name'}, inplace=True)\n",
    "    if new_col == 'account':\n",
    "        sfdc_advertiser_df.rename(columns={new_col: 'sfdc_account_id'}, inplace=True)\n",
    "    if new_col == 'related_rate_card':\n",
    "        sfdc_advertiser_df.rename(columns={new_col: 'sfdc_rate_card_id'}, inplace=True)\n",
    "sfdc_advertiser_df.columns.tolist()\n",
    "for col in sfdc_account_df.columns:\n",
    "    new_col = col.replace('__c', '').lower()\n",
    "    sfdc_account_df.rename(columns={col: new_col}, inplace=True)\n",
    "    if new_col == 'id':\n",
    "        sfdc_account_df.rename(columns={new_col: 'sfdc_account_id'}, inplace=True)\n",
    "    if new_col == 'name':\n",
    "        sfdc_account_df.rename(columns={new_col: 'sfdc_account_name'}, inplace=True)\n",
    "sfdc_account_df.columns.tolist()\n",
    "for col in sfdc_rate_card_df.columns:\n",
    "    new_col = col.replace('__c', '').lower()\n",
    "    sfdc_rate_card_df.rename(columns={col: new_col}, inplace=True)\n",
    "    if new_col == 'id':\n",
    "        sfdc_rate_card_df.rename(columns={new_col: 'sfdc_rate_card_id'}, inplace=True)\n",
    "    if new_col == 'name':\n",
    "        sfdc_rate_card_df.rename(columns={new_col: 'rate_card_name'}, inplace=True)\n",
    "sfdc_rate_card_df.columns.tolist()\n",
    "# sfdc_account_df['sfdc_account_id'] = sfdc_account_df['id']\n",
    "# sfdc_account_df['sfdc_account_name'] = sfdc_account_df['name']\n",
    "sfdc_account_df.sort_values(by='sfdc_account_id', inplace=True)\n",
    "# sfdc_advertiser_df['sfdc_advertiser_id'] = sfdc_advertiser_df['id']\n",
    "# sfdc_advertiser_df['sfdc_advertiser_name'] = sfdc_advertiser_df['name']\n",
    "# sfdc_advertiser_df['sfdc_account_id'] = sfdc_advertiser_df['account']\n",
    "\n",
    "sfdc_advertiser_df.sort_values(by=['sfdc_account_id', 'sfdc_advertiser_id', 'encoding_format_id', 'encoding_advertiser', 'encoding_product_code', 'encoding_module_code'], inplace=True)\n",
    "# # sfdc_account_df[['sfdc_account_id', 'sfdc_account_name']] \n",
    "sfdc_adv_account_df = sfdc_advertiser_df.merge(sfdc_account_df, how='left', on='sfdc_account_id', suffixes=('_adv', '_acc'))\n",
    "sfdc_adv_account_df = sfdc_adv_account_df[sfdc_adv_account_cols].copy()\n",
    "sfdc_rate_card_df = sfdc_rate_card_df[sfdc_rate_card_cols].copy()\n",
    "sfdc_adv_account_rate_card_df = sfdc_adv_account_df[sfdc_adv_account_cols].merge(sfdc_rate_card_df[sfdc_rate_card_cols], how='left', on='sfdc_rate_card_id', suffixes=('_adv', '_rc')).copy().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_list = ['product_code', 'product_name', 'donovan_agency_product_code', 'description', 'isci', 'project_name', 'advertiser', 'client_code',\n",
    "                   'cable_estimate', 'spot_estimate', 'campaign', 'audience', 'audience2', 'category', 'comercial_id', 'contour_id', 'creative_offer',\n",
    "                   'donovan_agency_advertiser_code', 'donovan_agency_estimate_code', 'eid', 'group', 'hd_sd', 'id', 'length', 'lob', 'media_type',\n",
    "                   'message', 'misc', 'module_code', 'offer', 'offer_2', 'phone_number', 'quality', 'revision', 'show_name', 'slug', 'sport_id',\n",
    "                   'sport_show_sub_category', 'spot_name', 'tag', 'text', 'title', 'veil_id', 'version_name', 'year']\n",
    "for attr in attributes_list:\n",
    "    encodings_df[attr] = encodings_df['attributes'].apply(lambda x: x.get(attr))\n",
    "# encodings_df['product_code'] = encodings_df['attributes'].apply(lambda x: x.get('product_code'))\n",
    "\n",
    "# Define conditions\n",
    "# Ensure 'description' column does not contain None values\n",
    "encodings_df['description'] = encodings_df['description'].fillna('')\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['product_code'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].notnull(),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['product_code'].isnull() & encodings_df['product_name'].isnull() & encodings_df['donovan_agency_product_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['product_code'],\n",
    "    encodings_df['product_name'],\n",
    "    encodings_df['donovan_agency_product_code'],\n",
    "    encodings_df['description'].str[26:30].str.strip(),\n",
    "    encodings_df['description'].str[6:10].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['product_code'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['isci'].notnull(),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].notnull(),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['isci'].isnull() & encodings_df['project_name'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['isci'],\n",
    "    encodings_df['project_name'],\n",
    "    encodings_df['description'].str[8:18].str.strip(),\n",
    "    encodings_df['description'].str[18:38].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['isci'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    encodings_df['advertiser'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['client_code'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['client_code'].isnull() & encodings_df['donovan_agency_advertiser_code'].notnull(),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & ~encodings_df['description'].str.startswith(('TV', 'RA')),\n",
    "    encodings_df['advertiser'].isnull() & encodings_df['project_name'].isnull() & encodings_df['donovan_agency_advertiser_code'].isnull() & encodings_df['description'].notnull() & encodings_df['description'].str.len() > 10 & encodings_df['description'].str.startswith(('TV', 'RA'))\n",
    "]\n",
    "\n",
    "# Define corresponding values\n",
    "choices = [\n",
    "    encodings_df['advertiser'],\n",
    "    encodings_df['client_code'],\n",
    "    encodings_df['donovan_agency_advertiser_code'],\n",
    "    encodings_df['description'].str[22:26].str.strip(),\n",
    "    encodings_df['description'].str[2:6].str.strip()\n",
    "]\n",
    "\n",
    "# Apply conditions and choices to create the new column\n",
    "encodings_df['advertiser'] = np.select(conditions, choices, default=None)\n",
    "\n",
    "#  new cell\n",
    "\n",
    "# sfdc_account_df['sfdc_account_id'] = sfdc_account_df['Id']\n",
    "# sfdc_account_df['sfdc_account_name'] = sfdc_account_df['Name']\n",
    "sfdc_bvs_customer_df['customer_id'] = sfdc_bvs_customer_df['customer_id__c'].astype(int)\n",
    "sfdc_bvs_customer_df['sfdc_account_id'] = sfdc_bvs_customer_df['Account__c']\n",
    "account_cols = ['sfdc_account_id', 'sfdc_account_name']\n",
    "customer_cols = ['customer_id', 'sfdc_account_id']\n",
    "sfdc_cust_account_df = sfdc_account_df[account_cols].merge(sfdc_bvs_customer_df[customer_cols], on='sfdc_account_id', how='inner', suffixes=('_sfdc_account', '_sfdc_customer'))\n",
    "# sfdc_cust_account_df['customer_id'] = sfdc_cust_account_df['customer_id__c'].astype(int)\n",
    "sfdc_cust_account_df\n",
    "sfdc_bvs_cust_account_df = sfdc_cust_account_df.merge(customers_df, left_on='customer_id', right_on='customer_id', how='inner', suffixes=('_sfdc', '_avs'))\n",
    "\n",
    "# new cell\n",
    "\n",
    "core_functions.rename_columns(encoder_groups_df, 'encoder_group_')\n",
    "core_functions.rename_columns(encoders_df, 'encoder_')\n",
    "core_functions.rename_columns(formats_df, 'format_')\n",
    "core_functions.rename_columns(customers_df, 'customer_')\n",
    "core_functions.rename_columns(profiles_df, 'profile_')\n",
    "core_functions.rename_columns(aeismaps_df, 'aeis_')\n",
    "\n",
    "encodings_df['encoding_id'] = encodings_df['encoding_id'].astype(int)\n",
    "encoders_groups_df = encoders_df.merge(encoder_groups_df, left_on='encoder_group_id', right_on='encoder_group_id', how='left')\n",
    "encoders_groups_df\n",
    "\n",
    "\n",
    "encodings_encoders_df = encodings_df.merge(encoders_groups_df, left_on='encoder_id', right_on='encoder_id', how='left', suffixes=('', '_dupe'))\n",
    "encodings_encoders_df\n",
    "\n",
    "aeismaps_df.sort_values(by=['aeis__encoding_id', 'aeis_id', ], inplace=True)\n",
    "aeismaps_df = aeismaps_df.loc[(aeismaps_df['aeis_id'].fillna(0.0).astype(int) > 0) & (aeismaps_df['aeis__encoding_id'].fillna(0.0).astype(int) > 0)]\n",
    "aeismaps_df.drop_duplicates(subset=('aeis__encoding_id' ), inplace=True)\n",
    "aeismaps_df\n",
    "\n",
    "encodings_aeis_df = encodings_encoders_df.merge(aeismaps_df, left_on='encoding_id', right_on='aeis__encoding_id', how='left')\n",
    "encodings_aeis_df\n",
    "\n",
    "formats_df['format__customer_id'] = formats_df['format__customer_id'].astype(int)\n",
    "formats_df['format__profile_id'] = formats_df['format__profile_id'].astype(int)\n",
    "sfdc_bvs_cust_account_df['customer_id'] = sfdc_bvs_cust_account_df['customer_id'].astype(int)\n",
    "formats_customers_df = formats_df.merge(sfdc_bvs_cust_account_df, left_on='format__customer_id', right_on='customer_id', how='left')\n",
    "formats_customers_df\n",
    "\n",
    "formats_customers_profiles_df = formats_customers_df.merge(profiles_df, left_on='format__profile_id', right_on='profile_id', how='left')\n",
    "formats_customers_profiles_df\n",
    "\n",
    "encodings_bvs_df = encodings_aeis_df.merge(formats_customers_profiles_df, on='format_id',  how='left', suffixes=('', '_drop'))\n",
    "for col in encodings_bvs_df.columns:\n",
    "    if col.endswith('_drop'):\n",
    "        encodings_bvs_df.drop(columns=col, inplace=True)\n",
    "encodings_bvs_df\n",
    "\n",
    "encodings_bvs_df['ad_prod_campaign'] = None\n",
    "encodings_bvs_df['advertiser'] = encodings_bvs_df['advertiser'].fillna('')\n",
    "encodings_bvs_df['product_code'] = encodings_bvs_df['product_code'].fillna('')\n",
    "encodings_bvs_df['campaign'] = encodings_bvs_df['campaign'].fillna('')\n",
    "\n",
    "# Update ad_prod_campaign\n",
    "encodings_bvs_df['ad_prod_campaign'] = encodings_bvs_df.apply(\n",
    "    lambda row: f\"{row['advertiser'].strip()}-{row['product_code'].strip()}-{row['campaign'].strip()}\".replace(' ', '_') if pd.isnull(row['ad_prod_campaign']) else row['ad_prod_campaign'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# new cell\n",
    "\n",
    "encodings_bvs_df.sort_values(by=['sfdc_account_id', 'format_id', 'profile_id', 'customer_id', 'encoding_id'], inplace=True)\n",
    "\n",
    "# new cell\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrames\n",
    "# encodings_bvs_df = pd.DataFrame(...)\n",
    "# sfdc_advertiser_df = pd.DataFrame(...)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Define a function to perform the updates\n",
    "# def update_encodings_bvs_df(encodings_bvs_df, sfdc_advertiser_df):\n",
    "#     # First update\n",
    "#     mask = encodings_bvs_df['ad_prod_campaign'].isnull()\n",
    "#     encodings_bvs_df.loc[mask, 'ad_prod_campaign'] = encodings_bvs_df[mask].apply(\n",
    "#         lambda row: f\"{row['advertiser'].strip()}-{row['product_code'].strip()}-{row['campaign'].strip()}\".replace(' ', '_'),\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     # Define a function to perform the updates based on conditions\n",
    "#     def update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, left_on, right_on, match_type):\n",
    "#         merged_df = encodings_bvs_df.merge(sfdc_advertiser_df, how='left', left_on=left_on, right_on=right_on)\n",
    "#         mask = (merged_df['sfdc_advertiser_id'].isnull()) & (merged_df['Encoding_Format_ID__c'].notnull()) & (merged_df['format_id'] == merged_df['Encoding_Format_ID__c']) & (merged_df['Match_Type__c'] == match_type)\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_id'] = merged_df.loc[mask, 'Id']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_name'] = merged_df.loc[mask, 'Name']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_advertiser_match_type'] = merged_df.loc[mask, 'Match_Type__c']\n",
    "#         encodings_bvs_df.loc[mask, 'sfdc_rate_card_id'] = merged_df.loc[mask, 'Related_Rate_Card__c']\n",
    "#         encodings_bvs_df.loc[mask, 'advertiser_updated'] = pd.Timestamp.now()\n",
    "\n",
    "#     # Apply updates based on different conditions\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code_multiple')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'product_code', 'Enc_Product_Code__c', 'encoding_product_code_ignore_format')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'advertiser', 'Enc_Advertiser__c', 'encoding_advertiser')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'advertiser', 'Enc_Advertiser__c', 'encoding_advertiser_ignore_format')\n",
    "#     update_with_conditions(encodings_bvs_df, sfdc_advertiser_df, 'format_id', 'Encoding_Format_ID__c', 'encoding_format')\n",
    "\n",
    "# # Call the function to update the DataFrame\n",
    "# update_encodings_bvs_df(encodings_bvs_df, sfdc_advertiser_df)\n",
    "\n",
    "# print(encodings_bvs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting with {len(encodings_bvs_df)} rows\")\n",
    "accounted_for = 0\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoding_product_code_multiple'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoding_product_code_multiple_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_product_code_multiple_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoding_product_code'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoding_product_code_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_product_code_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoding_advertiser'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoding_advertiser_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_advertiser_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoding_advertiser_ignore_format'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoding_advertiser_ignore_format_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_advertiser_ignore_format_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoding_format'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoding_format_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoding_format_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "print(\"finished normal matches\")\n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'encoder_group'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "encoder_group_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(encoder_group_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'] == 'Clone'\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "clone_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(clone_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "mask = sfdc_advertiser_df['match_type'].isna()\n",
    "print(len(sfdc_advertiser_df.loc[mask]))\n",
    "null_match_sfdc_advertiser_df = sfdc_advertiser_df.loc[mask].copy()\n",
    "accounted_for += len(null_match_sfdc_advertiser_df)\n",
    "print(f\"Accounted for {accounted_for} rows\")\n",
    "print(f\"Started with {len(sfdc_advertiser_df)} rows and accounted for {accounted_for} rows\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# array(['encoding_format', 'encoder_group', 'Clone',\n",
    "    #    'encoding_product_code_multiple', None, 'encoding_advertiser',\n",
    "    #    'encoding_product_code', 'encoding_advertiser_ignore_format'],\n",
    "    #   dtype=object)\n",
    "# 14327 total\n",
    "# encoding_format: 14174\n",
    "# encoder_group: 32\n",
    "# Clone: 2\n",
    "# encoding_product_code_multiple: 17\n",
    "# encoding_advertiser: 7\n",
    "# encoding_product_code: 37\n",
    "# encoding_advertiser_ignore_format: 45\n",
    "#  null: 13\n",
    "print(14327 - 14174 - 32 - 2 - 17 - 7 - 37 - 45 - 13)\n",
    "sfdc_advertiser_df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles_df.loc[profiles_df['profile__default_asset_code'] != 'isci']\n",
    "\n",
    "# expanded_df = profiles_df['profile__attributes'].apply(pd.Series)\n",
    "\n",
    "# # Combine the original DataFrame with the expanded DataFrame\n",
    "# result_df = pd.concat([profiles_df, expanded_df], axis=1)\n",
    "# core_functions.show_more_dataframe()\n",
    "# result_df\n",
    "        # CASE WHEN (e.attributes.product_code is NOT NULL) THEN e.attributes.product_code\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NOT NULL) THEN e.attributes.product_name\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NOT NULL) THEN e.attributes.donovan_agency_product_code\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NULL and e.attributes.description is not null and length(e.attributes.description) > 10 and (e.attributes.description not like 'TV%' or e.attributes.description not like 'RA%')) THEN trim(substring(e.attributes.description, 27,4))\n",
    "        # WHEN (e.attributes.product_code is NULL AND e.attributes.product_name is NULL AND e.attributes.donovan_agency_product_code is NULL and e.attributes.description is not null and length(e.attributes.description) > 10 and (e.attributes.description  like 'TV%' or e.attributes.description  like 'RA%')) THEN trim(substring(e.attributes.description, 7,4))\n",
    "        # ELSE NULL END AS product_code,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_bvs_encoding_product_code_multiple_sfdc_advertiser_df = encodings_bvs_df.merge(encoding_product_code_multiple_sfdc_advertiser_df, left_on='format_id', right_on='encoding_format_id', how='left', suffixes=('', '_encoding_format')).dropna(subset=['sfdc_advertiser_id'])\n",
    "print(f\"Starting with {len(encodings_bvs_df)} rows\")\n",
    "print(f\"Accounted for {len(encoding_product_code_multiple_sfdc_advertiser_df)} rows\")\n",
    "# [\"ALDR\", \"ALGM\", \"ALHP\"]\n",
    "\n",
    "# new cell\n",
    "\n",
    "encoding_product_code_multiple_sfdc_advertiser_df['product_code_list_list'] = encoding_product_code_multiple_sfdc_advertiser_df['product_code_list'].apply(lambda x: x.split(','))\n",
    "\n",
    "# new cell\n",
    "\n",
    "# Filter the main DataFrame to include only relevant sfdc_account_ids\n",
    "meta_df = encoding_product_code_multiple_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['product_code'].fillna('', inplace=True)\n",
    "# working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "\n",
    "# Explode product_code_list_list into multiple rows\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "encoding_expanded_df = encoding_expanded_df.explode('product_code_list_list')\n",
    "encoding_expanded_df['product_code_list_list'] = encoding_expanded_df['product_code_list_list'].str.replace('\"', '').copy()\n",
    "encoding_expanded_df['encoding_format_id'] = encoding_expanded_df['encoding_format_id'].astype(int)\n",
    "encoding_expanded_df[['product_code_list_list', 'encoding_format_id', 'sfdc_advertiser_id']]\n",
    "# encoding_expanded_master_df = encoding_expanded_df.sort_values(by=['encoding_format_id', 'product_code_list_list'], inplace=True)\n",
    "encoding_expanded_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df.drop_duplicates(subset=['encoding_format_id', 'product_code_list_list'], keep='first', inplace=True)\n",
    "# encoding_expanded_master_df['encoding_format_id'].fillna('0', inplace=True)\n",
    "# encoding_expanded_master_df['product_code_list_list'].fillna('', inplace=True)\n",
    "# encoding_expanded_master2_df = encoding_expanded_master_df.drop_duplicates(subset=['encoding_format_id', 'product_code_list_list'], keep='first')\n",
    "# len(encoding_expanded_master2_df)\n",
    "working_df['format_id'] = working_df['format_id'].astype(int)\n",
    "# Perform the merge based on format_id and product_code\n",
    "merged_df = working_df.merge(\n",
    "    encoding_expanded_df,\n",
    "    left_on=['format_id', 'product_code'],\n",
    "    right_on=['encoding_format_id', 'product_code_list_list'],\n",
    "    how='left', suffixes=('', '_encoding_format')\n",
    ")\n",
    "merged_df = merged_df.dropna(subset=['sfdc_advertiser_id'])\n",
    "merged_df['encoding_id'] = merged_df['encoding_id'].astype(int)\n",
    "working_df['encoding_id'] = working_df['encoding_id'].astype(int)\n",
    "merged_df[['encoding_id','sfdc_account_id']]\n",
    "print(f\"Starting with {len(working_df)} rows\")\n",
    "working_df2 = working_df.merge(merged_df[['encoding_id', 'sfdc_advertiser_id']], on='encoding_id', how='left',)\n",
    "print(f\"Accounted for {len(working_df2)} rows\")\n",
    "working_df2.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "# # Assign the advertiser ID to the original DataFrame\n",
    "# working_df['sfdc_advertiser_id'] = merged_df['sfdc_advertiser_id']\n",
    "# # working_df.dropna(subset=['sfdc_advertiser_id'])\n",
    "# working_df\n",
    "working_df2.columns.tolist()\n",
    "\n",
    "new_encodings_bvs_df = pd.DataFrame(columns=working_df2.columns)\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, working_df2], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "\n",
    "# new cell\n",
    "\n",
    "meta_df = encoding_product_code_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['product_code'].fillna('', inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "# working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id', 'encoding_product_code', 'product_code']]\n",
    "encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "encoding_expanded_df.rename(columns={'enc_product_code': 'product_code'}, inplace=True)\n",
    "encoding_expanded_df\n",
    "encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id', 'product_code']].copy()\n",
    "encoding_expanded_slim_df\n",
    "\n",
    "merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id', 'product_code'], how='left')\n",
    "merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "merged_df\n",
    "new_encodings_bvs_df\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "\n",
    "# new cell\n",
    "\n",
    "# encoding_product_code_ignore_format\n",
    "meta_df =encoding_advertiser_ignore_format_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['product_code'].fillna('', inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id',  'encoding_product_code', 'product_code']]\n",
    "# encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "encoding_expanded_df.rename(columns={'enc_product_code': 'product_code'}, inplace=True)\n",
    "encoding_expanded_df\n",
    "encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id',  'product_code']].copy()\n",
    "encoding_expanded_slim_df\n",
    "\n",
    "merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id',  'product_code'], how='left')\n",
    "merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "merged_df\n",
    "new_encodings_bvs_df\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "\n",
    "# new cell\n",
    "\n",
    "# encoding_advertiser\n",
    "meta_df = encoding_advertiser_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['advertiser'].fillna('', inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id', 'enc_advertiser']]\n",
    "encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "encoding_expanded_df\n",
    "encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id', 'advertiser']].copy()\n",
    "encoding_expanded_slim_df\n",
    "\n",
    "merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id', 'advertiser'], how='left')\n",
    "merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "merged_df\n",
    "new_encodings_bvs_df\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "\n",
    "# new cell\n",
    "\n",
    "# encoding_advertiser_ignore_format\n",
    "meta_df = encoding_advertiser_ignore_format_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['advertiser'].fillna('', inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id',  'enc_advertiser']]\n",
    "# encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "encoding_expanded_df\n",
    "encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id',  'advertiser']].copy()\n",
    "encoding_expanded_slim_df\n",
    "\n",
    "merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'advertiser'], how='left')\n",
    "merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "merged_df\n",
    "new_encodings_bvs_df\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "\n",
    "\n",
    "# new cell\n",
    "\n",
    "# encoding_format\n",
    "meta_df = encoding_format_sfdc_advertiser_df\n",
    "sfdc_account_ids = meta_df['sfdc_account_id'].unique().tolist()\n",
    "working_df = encodings_bvs_df[(encodings_bvs_df['sfdc_account_id'].isin(sfdc_account_ids)) & ~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))].copy()\n",
    "\n",
    "# Ensure 'product_code' column is filled with empty strings for null values\n",
    "working_df['advertiser'].fillna('', inplace=True)\n",
    "if 'sfdc_advertiser_id' in working_df.columns:\n",
    "    working_df.drop(columns=['sfdc_advertiser_id'], inplace=True)\n",
    "encoding_expanded_df = meta_df.copy()\n",
    "\n",
    "encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_name', 'sfdc_advertiser_id', 'encoding_format_id']]\n",
    "encoding_expanded_df.rename(columns={'encoding_format_id': 'format_id'}, inplace=True)\n",
    "# encoding_expanded_df.drop(columns=['product_code'], inplace=True)\n",
    "# encoding_expanded_df.rename(columns={'enc_advertiser': 'advertiser'}, inplace=True)\n",
    "encoding_expanded_df\n",
    "encoding_expanded_df = encoding_expanded_df.dropna(subset=['sfdc_advertiser_id']).copy()\n",
    "encoding_expanded_slim_df = encoding_expanded_df[['sfdc_account_id', 'sfdc_advertiser_id', 'format_id']].copy()\n",
    "encoding_expanded_slim_df\n",
    "\n",
    "merged_df = working_df.merge(encoding_expanded_slim_df, on=['sfdc_account_id', 'format_id'], how='left')\n",
    "merged_df.dropna(subset=['sfdc_advertiser_id'], inplace=True)\n",
    "merged_df\n",
    "new_encodings_bvs_df\n",
    "new_encodings_bvs_df = pd.concat([new_encodings_bvs_df, merged_df], ignore_index=True)\n",
    "new_encodings_encodings_ids = new_encodings_bvs_df['encoding_id'].unique().tolist()\n",
    "len(new_encodings_bvs_df)\n",
    "# 1686537\n",
    "\n",
    "# new cell\n",
    "\n",
    "new_encodings_bvs_df.sort_values(by=['sfdc_account_id', 'sfdc_advertiser_id','format_id', 'profile_id', 'customer_id', 'encoding_id'], inplace=True)\n",
    "\n",
    "# new cell\n",
    "\n",
    "# new_encodings_bvs_merge_df = new_encodings_bvs_df[['encoding_id', 'sfdc_advertiser_id']].drop_\n",
    "# new_encodings_bvs_merge_df\n",
    "# encodings_bvs_df_to_write = encodings_bvs_df.merge(new_encodings_bvs_merge_df, on='encoding_id', how='left')\n",
    "# encodings_bvs_df_to_write\n",
    "len(encodings_bvs_df)\n",
    "len(encodings_bvs_df[~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))]) + len(new_encodings_bvs_df)\n",
    "encodings_bvs_df['sfdc_advertiser_id'] = ''\n",
    "# 1686537\n",
    "# 1686866\n",
    "encodings_bvs_df_to_write = pd.concat([encodings_bvs_df[~(encodings_bvs_df['encoding_id'].isin(new_encodings_encodings_ids))], new_encodings_bvs_df], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "# new cell\n",
    "\n",
    "# encodings_bvs_df_to_write.sort_values(by=['sfdc_account_id'], inplace=True)\n",
    "billing_last_updated = pd.Timestamp.now()\n",
    "encodings_bvs_df_to_write['billing_last_updated'] = billing_last_updated\n",
    "billing_last_audit_id = core_functions.generate_uuid()\n",
    "encodings_bvs_df_to_write['billing_last_audit_id'] = billing_last_audit_id\n",
    "# encodings_bvs_df_to_write\n",
    "\n",
    "# new cell\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "int_cols = ['encoding_id','encoder_group_id']\n",
    "# encodings_bvs_df_to_write[]\n",
    "# print(encodings_bvs_df_to_write.dtypes)\n",
    "# encodings_bvs_df_to_write['aeis_id'].isna()\n",
    "mask = encodings_bvs_df_to_write['aeis_id'].isna()\n",
    "encodings_bvs_df_to_write[mask,[['encoding_id','encoded_timestamp']]]\n",
    "\n",
    "# new cell\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "process_df = encodings_bvs_df_to_write[0:10000].copy()\n",
    "\n",
    "nested_columns = ['attributes']\n",
    "for col in nested_columns:\n",
    "    process_df[col] = process_df[col].apply(lambda x: json.dumps(x) if pd.notna(x) else '')\n",
    "    \n",
    "def parse_iso_with_timezone(ts):\n",
    "    # Replace timezone colon\n",
    "    ts = ts.replace(\":\", \"\", 1) if \"+\" in ts or \"-\" in ts else ts\n",
    "    return datetime.strptime(ts, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "\n",
    "# parsed_timestamps = [parse_iso_with_timezone(ts) for ts in process_df['encoded_timestamp'] ]\n",
    "process_df['encoded_timestamp'] = process_df['encoded_timestamp'].apply(parse_iso_with_timezone)\n",
    "\n",
    "# print(parsed_timestamps)\n",
    "# process_df['encoded_timestamp'] = pd.to_datetime(process_df['encoded_timestamp'])\n",
    "# process_df = core_functions.convert_to_string_except_exclusions(process_df, exclude_columns=['encoded_timestamp', 'encoding_id', 'format_id','customer_id', 'profile_id', 'billing_last_updated', 'deleted', 'profile_deleted'])\n",
    "# process_df.drop(columns=['attributes'], inplace=True)\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "n90_storage_options = config.get('N90_GCS_STORAGE_OPTIONS')\n",
    "\n",
    "veil_billing_bucket = config.get('veil_billing').get('billing_gcs_bucket_id')\n",
    "process_df['encoded_timestamp']\n",
    "# process_df['profile__attributes']\n",
    "# n90_bucket = 'n90_veil_partner'\n",
    "# veil_output_prefix = 'encodings'\n",
    "# n90_output_prefix = 'advocado-looker/avs_prod/encodings'\n",
    "# partition_cols = ['sfdc_account_id']\n",
    "# core_functions.write_hive_partitioned_parquet(process_df, veil_billing_bucket, veil_output_prefix, partition_cols, veil_storage_options)\n",
    "# print(f\"Finished writing to {veil_billing_bucket}/{veil_output_prefix}\")\n",
    "# core_functions.write_hive_partitioned_parquet(process_df, n90_bucket, n90_output_prefix, partition_cols, n90_storage_options)\n",
    "# print(f\"Finished writing to {n90_bucket}/{n90_output_prefix}\")\n",
    "\n",
    "# new cell\n",
    "\n",
    "print(encodings_bvs_df_to_write.dtypes)\n",
    "\n",
    "\n",
    "# new cell\n",
    "\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "veil_storage_options = config.get('VEIL_GCS_STORAGE_OPTIONS')\n",
    "n90_storage_options = config.get('N90_GCS_STORAGE_OPTIONS')\n",
    "n90_storage_options\n",
    "veil_billing_bucket = config.get('veil_billing').get('billing_gcs_bucket_id')\n",
    "veil_billing_bucket\n",
    "# n90_bucket = 'n90_veil_partner'\n",
    "# veil_output_prefix = 'encodings'\n",
    "# n90_output_prefix = 'advocado-looker/avs_prod/encodings'\n",
    "# partition_cols = ['sfdc_account_id']\n",
    "\n",
    "# core_functions.write_hive_partitioned_parquet(encodings_bvs_df_to_write, n90_bucket, n90_output_prefix, partition_cols, n90_storage_options)\n",
    "# print(f\"Finished writing to {n90_bucket}/{n90_output_prefix}\")\n",
    "\n",
    "# new cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
