{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT\n",
    "Make sure all core_functions and configs are loaded before running this stand alone version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install matplotlib folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_N90_CORE_APPS')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_ADHOC_BILLING')\n",
    "# Query to extract relevant data from BigQuery\n",
    "query = \"\"\"\n",
    "WITH geo_changes AS (\n",
    "  SELECT\n",
    "    ip_address,\n",
    "    zip_code,\n",
    "    neustar_country as country,\n",
    "    neustar_state as start,\n",
    "    timestamp,\n",
    "    LAG(zip_code) OVER (PARTITION BY ip_address ORDER BY timestamp) AS prev_zip_code,\n",
    "    LAG(timestamp) OVER (PARTITION BY ip_address ORDER BY timestamp) AS prev_timestamp\n",
    "  FROM `bigquery-sandbox-393916.looker.pageviews`\n",
    "  WHERE neustar_country in ('us', 'ca')\n",
    ")\n",
    "SELECT\n",
    "  ip_address,\n",
    "  zip_code,\n",
    "  prev_zip_code,\n",
    "  timestamp,\n",
    "  prev_timestamp,\n",
    "  TIMESTAMP_DIFF(timestamp, prev_timestamp, DAY) AS stability_duration_days\n",
    "FROM geo_changes\n",
    "WHERE prev_timestamp IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and load results into a Pandas DataFrame\n",
    "print(\"Querying BigQuery...\")\n",
    "\n",
    "df = core_functions.fetch_gbq_data(query, bigquery_client)\n",
    "# query_job = client.query(query)\n",
    "# results = query_job.result()\n",
    "# df = results.to_dataframe()\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Calculating metrics...\")\n",
    "\n",
    "# Filter for rows where the zip code changed\n",
    "df['has_changed'] = df['zip_code'] != df['prev_zip_code']\n",
    "changes = df[df['has_changed']]\n",
    "\n",
    "# Calculate stability metrics\n",
    "stability_metrics = changes.groupby('ip_address').agg(\n",
    "    avg_stability_duration_days=('stability_duration_days', 'mean'),\n",
    "    max_stability_duration_days=('stability_duration_days', 'max'),\n",
    "    min_stability_duration_days=('stability_duration_days', 'min'),\n",
    "    change_count=('stability_duration_days', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate overall statistics\n",
    "overall_avg_stability = stability_metrics['avg_stability_duration_days'].mean()\n",
    "overall_max_stability = stability_metrics['max_stability_duration_days'].max()\n",
    "overall_min_stability = stability_metrics['min_stability_duration_days'].min()\n",
    "\n",
    "# Print insights\n",
    "print(\"\\n--- Insights ---\")\n",
    "print(f\"Overall Average Stability Duration (days): {overall_avg_stability:.2f}\")\n",
    "print(f\"Overall Max Stability Duration (days): {overall_max_stability}\")\n",
    "print(f\"Overall Min Stability Duration (days): {overall_min_stability}\")\n",
    "\n",
    "# Suggest a cache age based on overall average stability\n",
    "recommended_cache_age = int(overall_avg_stability * 0.8)  # Set to 80% of the average stability\n",
    "print(f\"\\nRecommended Cache Age (days): {recommended_cache_age}\")\n",
    "\n",
    "# Save stability metrics to CSV for further analysis\n",
    "stability_metrics.to_csv(\"ip_stability_metrics.csv\", index=False)\n",
    "print(\"\\nStability metrics saved to 'ip_stability_metrics.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = config.get('SA_N90_CORE_APPS')\n",
    "map_geo_sql = f\"\"\"\n",
    "    SELECT geo_location as zip_code, geo_city as city, geo_country as country, geo_state as state,\n",
    "geo_latitude as latitude, geo_longitude as longitude\n",
    "\n",
    "from `next90-core-applications.next90_analytics.geos` WHERE geo_type = 'zip' \n",
    "AND geo_country in ('United States', 'Canada')\n",
    "\"\"\"\n",
    "city_reference = core_functions.fix_df_dtypes(core_functions.fetch_gbq_data(query=map_geo_sql, bigquery_client=n90_bigquery_client))\n",
    "\n",
    "city_reference.head()\n",
    "city_reference.loc[city_reference['country'] != 'United States']\n",
    "changes['zip_code'] = changes['zip_code'].apply(lambda x: str(x).upper().replace(' ', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stability_metrics_2 = changes.groupby(['ip_address', 'zip_code']).agg(\n",
    "    avg_stability_duration_days=('stability_duration_days', 'mean'),\n",
    "    max_stability_duration_days=('stability_duration_days', 'max'),\n",
    "    min_stability_duration_days=('stability_duration_days', 'min'),\n",
    "    change_count=('stability_duration_days', 'count')\n",
    ").reset_index()\n",
    "\n",
    "stability_metrics_2['zip_code'] = stability_metrics_2['zip_code'].apply(lambda x: str(x).upper().replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(stability_metrics_2, city_reference, on='zip_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from matplotlib import cm\n",
    "\n",
    "# Merge stability metrics with city reference DataFrame\n",
    "merged_df = pd.merge(stability_metrics_2, city_reference, on='zip_code', how='left')\n",
    "\n",
    "# Group by city and calculate volatility metrics\n",
    "city_volatility = merged_df.groupby(['city', 'country', 'latitude', 'longitude']).agg(\n",
    "    avg_stability_duration=('avg_stability_duration_days', 'mean'),\n",
    "    total_ip_count=('ip_address', 'count'),\n",
    "    total_change_count=('change_count', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate recommended cache duration\n",
    "city_volatility['recommended_cache_duration'] = (city_volatility['avg_stability_duration'] * 0.8).round()\n",
    "\n",
    "# Normalize cache durations for color gradient\n",
    "max_cache_duration = city_volatility['recommended_cache_duration'].max()\n",
    "min_cache_duration = city_volatility['recommended_cache_duration'].min()\n",
    "norm = cm.colors.Normalize(vmin=min_cache_duration, vmax=max_cache_duration)\n",
    "color_map = cm.ScalarMappable(norm=norm, cmap='YlOrRd')\n",
    "\n",
    "# Create a Folium map centered on North America\n",
    "map_center = [40.0, -100.0]\n",
    "m = folium.Map(location=map_center, zoom_start=4, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Add cities to the map\n",
    "for _, row in city_volatility.iterrows():\n",
    "    color = color_map.to_rgba(row['recommended_cache_duration'])\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=10,\n",
    "        color=None,\n",
    "        fill=True,\n",
    "        fill_color=cm.colors.rgb2hex(color[:3]),\n",
    "        fill_opacity=0.7,\n",
    "        popup=folium.Popup(\n",
    "            f\"<b>City:</b> {row['city']}<br>\"\n",
    "            f\"<b>Country:</b> {row['country']}<br>\"\n",
    "            f\"<b>Cache Duration (days):</b> {row['recommended_cache_duration']}\",\n",
    "            max_width=300\n",
    "        )\n",
    "    ).add_to(m)\n",
    "\n",
    "# Save the map to an HTML file and display it\n",
    "map_file = \"city_ip_cache_map.html\"\n",
    "m.save(map_file)\n",
    "print(f\"Map saved to {map_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Group by state and calculate volatility metrics\n",
    "state_volatility = merged_df.groupby(['state', 'country', 'latitude', 'longitude']).agg(\n",
    "    avg_stability_duration=('avg_stability_duration_days', 'mean'),\n",
    "    total_ip_count=('ip_address', 'count'),\n",
    "    total_change_count=('change_count', 'sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate recommended cache duration as 80% of the average stability duration\n",
    "state_volatility['recommended_cache_duration'] = (state_volatility['avg_stability_duration'] * 0.8).round()\n",
    "state_ip_summary = merged_df.groupby(['state', 'country']).agg(\n",
    "    avg_stability_duration=('avg_stability_duration_days', 'mean'),\n",
    "    total_ip_count=('ip_address', 'count'),\n",
    "    total_change_count=('change_count', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "state_ip_summary['recommended_cache_duration'] = (state_ip_summary['avg_stability_duration'] * 0.8).round()\n",
    "state_ip_summary.head()\n",
    "state_reference = state_ip_summary.copy()\n",
    "\n",
    "# Load GeoJSON for US states and Canadian provinces\n",
    "with open(\"geo-json/us-states.geo.json\", \"r\") as us_file, open(\"geo-json/canada_provinces.geo.json\", \"r\") as ca_file:\n",
    "    us_geojson = json.load(us_file)\n",
    "    ca_geojson = json.load(ca_file)\n",
    "\n",
    "# Combine GeoJSONs\n",
    "geojson_data = {\"type\": \"FeatureCollection\", \"features\": us_geojson[\"features\"] + ca_geojson[\"features\"]}\n",
    "\n",
    "# Add average stability duration and cache duration to GeoJSON properties\n",
    "for feature in geojson_data[\"features\"]:\n",
    "    state_name = feature[\"properties\"][\"name\"]\n",
    "    match = state_reference[state_reference[\"state\"] == state_name]\n",
    "    if not match.empty:\n",
    "        feature[\"properties\"][\"avg_stability_duration\"] = match.iloc[0][\"avg_stability_duration\"]\n",
    "        feature[\"properties\"][\"recommended_cache_duration\"] = match.iloc[0][\"recommended_cache_duration\"]\n",
    "    else:\n",
    "        feature[\"properties\"][\"avg_stability_duration\"] = \"No data\"\n",
    "        feature[\"properties\"][\"recommended_cache_duration\"] = \"No data\"\n",
    "\n",
    "# Normalize cache durations for color gradient\n",
    "max_cache_duration = state_reference['recommended_cache_duration'].max()\n",
    "min_cache_duration = state_reference['recommended_cache_duration'].min()\n",
    "norm = cm.colors.Normalize(vmin=min_cache_duration, vmax=max_cache_duration)\n",
    "color_map = cm.ScalarMappable(norm=norm, cmap='YlOrRd')\n",
    "\n",
    "# Function to get color for a state/province\n",
    "def get_color(state_name):\n",
    "    match = state_reference[state_reference[\"state\"] == state_name]\n",
    "    if not match.empty:\n",
    "        cache_duration = match.iloc[0][\"recommended_cache_duration\"]\n",
    "        return cm.colors.rgb2hex(color_map.to_rgba(cache_duration)[:3])\n",
    "    return \"#d3d3d3\"  # Default gray for states not in the data\n",
    "\n",
    "# Create a Folium map centered on North America\n",
    "map_center = [50.0, -100.0]\n",
    "m = folium.Map(location=map_center, zoom_start=4, tiles=\"CartoDB positron\")\n",
    "\n",
    "# Add GeoJSON to the map\n",
    "folium.GeoJson(\n",
    "    geojson_data,\n",
    "    style_function=lambda feature: {\n",
    "        \"fillColor\": get_color(feature[\"properties\"][\"name\"]),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 1,\n",
    "        \"fillOpacity\": 0.7,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=[\"name\", \"avg_stability_duration\", \"recommended_cache_duration\"],\n",
    "        aliases=[\"State/Province:\", \"Avg Stability Duration (days):\", \"Recommended Cache Duration (days):\"],\n",
    "        localize=True\n",
    "    )\n",
    ").add_to(m)\n",
    "\n",
    "# Add a legend\n",
    "legend_html = \"\"\"\n",
    "<div style=\"position: fixed; \n",
    "            bottom: 50px; left: 50px; width: 200px; height: 140px; \n",
    "            background-color: white; border:2px solid grey; z-index:9999; font-size:14px;\n",
    "            padding: 10px;\">\n",
    "    <b>Cache Duration (days)</b><br>\n",
    "    <i style=\"background: #ffffb2; width: 20px; height: 20px; float: left; margin-right: 5px;\"></i> Low<br>\n",
    "    <i style=\"background: #fecc5c; width: 20px; height: 20px; float: left; margin-right: 5px;\"></i> Medium<br>\n",
    "    <i style=\"background: #fd8d3c; width: 20px; height: 20px; float: left; margin-right: 5px;\"></i> High<br>\n",
    "    <i style=\"background: #e31a1c; width: 20px; height: 20px; float: left; margin-right: 5px;\"></i> Very High<br>\n",
    "</div>\n",
    "\"\"\"\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "# Save the map to an HTML file and display it\n",
    "map_file = \"state_province_ip_cache_map.html\"\n",
    "m.save(map_file)\n",
    "print(f\"Map saved to {map_file}\")\n",
    "state_reference.to_csv('state_ip_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
